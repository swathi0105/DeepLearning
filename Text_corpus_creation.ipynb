{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Text corpus creation and binary classification using DNN**"
      ],
      "metadata": {
        "id": "QUs1T8oeWNT0"
      },
      "id": "QUs1T8oeWNT0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "1EIx4ntQWZ1c"
      },
      "id": "1EIx4ntQWZ1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa9467a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daa9467a",
        "outputId": "739bcfd2-b739-417e-8885-b265b83a15e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "nltk.download('wordnet')\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "KxCXd-vhVhI_"
      },
      "id": "KxCXd-vhVhI_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7252ce0",
      "metadata": {
        "id": "d7252ce0"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('text_pdl5.csv',encoding='cp1252')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c166ee39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c166ee39",
        "outputId": "3e9a5dc4-bb42-43d8-bf83-2a1b23f0aca2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eabc9e4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eabc9e4b",
        "outputId": "b453156f-d80f-465e-bebe-0066833c5a55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['X', 'Y'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data"
      ],
      "metadata": {
        "id": "Tqc1dRBIWjZt"
      },
      "id": "Tqc1dRBIWjZt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bb15c6a",
      "metadata": {
        "id": "7bb15c6a"
      },
      "outputs": [],
      "source": [
        "x=df[\"X\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10d7720e",
      "metadata": {
        "id": "10d7720e"
      },
      "outputs": [],
      "source": [
        "y=df[\"Y\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ae665ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ae665ab",
        "outputId": "ee1ab731-723d-4f46-eadf-51c0fc366529"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    If you want to \\achieve greatness stop asking ...\n",
              "1    Success is walking from failure to failure wit...\n",
              "2    Trust because you are willing to accept the ri...\n",
              "3    Just when the caterpillar thought the world wa...\n",
              "4    Whenever you see a successful person you only ...\n",
              "Name: X, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69d81817",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69d81817",
        "outputId": "84a2fb2f-b2d8-42d0-e52f-db04d6e86635"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "Name: Y, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "292a7ee9",
      "metadata": {
        "id": "292a7ee9"
      },
      "outputs": [],
      "source": [
        "lemmatizer=WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "ucEJZQN2XCA_"
      },
      "id": "ucEJZQN2XCA_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop words removal"
      ],
      "metadata": {
        "id": "NtpjBSANXErv"
      },
      "id": "NtpjBSANXErv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b16b61f9",
      "metadata": {
        "id": "b16b61f9"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "## Remove stop words\n",
        "stops = set(stopwords.words(\"english\"))\n",
        "text = [ps.stem(w) for w in df if not w in stops and len(w) >= 3]\n",
        "text = list(set(df)) #remove duplicates\n",
        "text = \" \".join(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48402357",
      "metadata": {
        "id": "48402357"
      },
      "outputs": [],
      "source": [
        "def clean_review(review):\n",
        "\n",
        "    tokens = review.lower().split()\n",
        "    filtered_tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
        "    return \" \".join(filtered_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada5e7df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ada5e7df",
        "outputId": "79a5229e-6ddf-4e6b-bc15-3bec886701de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "temp=x.tolist()\n",
        "fax=[]\n",
        "for i in temp:\n",
        "    fax.append(clean_review(i))\n",
        "n_X=pd.Series(fax)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find unique word list and build a term  frequency matrix (you can use TF IDF features)"
      ],
      "metadata": {
        "id": "6la--eW3XJ5u"
      },
      "id": "6la--eW3XJ5u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79d7113c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "79d7113c",
        "outputId": "7b536336-f6c1-45a0-fb7a-a9b8d4e69b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         000        10  absolutely    accept   achieve  actually     again  \\\n",
              "0   0.000000  0.000000    0.000000  0.000000  0.421858  0.000000  0.000000   \n",
              "1   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "2   0.000000  0.000000    0.000000  0.421858  0.000000  0.000000  0.000000   \n",
              "3   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "4   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "5   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "6   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "7   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "8   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "9   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "10  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "11  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "12  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "13  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "14  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "15  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "16  0.392348  0.392348    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "17  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "18  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "19  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "20  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "21  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "22  0.000000  0.000000    0.000000  0.000000  0.000000  0.414672  0.000000   \n",
              "23  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "24  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "25  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.294323   \n",
              "26  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "27  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "28  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "29  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "30  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "31  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "32  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "33  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "34  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "35  0.000000  0.000000    0.388688  0.000000  0.000000  0.000000  0.000000   \n",
              "36  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "37  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "38  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "39  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "40  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "       alone    always       ant  ...  whenever   willing      work   working  \\\n",
              "0   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "1   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "2   0.000000  0.000000  0.000000  ...  0.000000  0.379567  0.000000  0.000000   \n",
              "3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "4   0.000000  0.000000  0.000000  ...  0.283653  0.000000  0.000000  0.000000   \n",
              "5   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "6   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.582124  0.000000   \n",
              "7   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "8   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "9   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "10  0.000000  0.000000  0.000000  ...  0.000000  0.418642  0.000000  0.000000   \n",
              "11  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "12  0.142261  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "13  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "14  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "15  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "16  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.353015  0.000000   \n",
              "17  0.000000  0.751466  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "18  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "19  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "20  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "21  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "22  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "23  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "24  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "25  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "26  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "27  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "28  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "29  0.000000  0.000000  0.308663  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "30  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "31  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "32  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "33  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "34  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.353553   \n",
              "35  0.000000  0.349721  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "36  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "37  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "38  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "39  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "40  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "       world     worst     wrong       yet       you  yourself  \n",
              "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "3   0.373294  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "5   0.323526  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "8   0.000000  0.000000  0.395045  0.000000  0.000000  0.000000  \n",
              "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "16  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "18  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "20  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "21  0.000000  0.000000  0.000000  0.000000  0.338813  0.000000  \n",
              "22  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "23  0.000000  0.000000  0.000000  0.557526  0.000000  0.000000  \n",
              "24  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "25  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "26  0.000000  0.000000  0.000000  0.000000  0.000000  0.439257  \n",
              "27  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "28  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "29  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "30  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "31  0.000000  0.358778  0.000000  0.000000  0.322810  0.000000  \n",
              "32  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "33  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "34  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "35  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "36  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "37  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "38  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "39  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "40  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "\n",
              "[41 rows x 218 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfd0411b-77be-4b5d-97d3-c4224c323e53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>accept</th>\n",
              "      <th>achieve</th>\n",
              "      <th>actually</th>\n",
              "      <th>again</th>\n",
              "      <th>alone</th>\n",
              "      <th>always</th>\n",
              "      <th>ant</th>\n",
              "      <th>...</th>\n",
              "      <th>whenever</th>\n",
              "      <th>willing</th>\n",
              "      <th>work</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>worst</th>\n",
              "      <th>wrong</th>\n",
              "      <th>yet</th>\n",
              "      <th>you</th>\n",
              "      <th>yourself</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.421858</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.421858</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.379567</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.373294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.283653</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.323526</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.582124</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.395045</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.418642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142261</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.392348</td>\n",
              "      <td>0.392348</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.353015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.751466</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.338813</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.414672</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.557526</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.294323</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.439257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.308663</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.358778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.322810</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.353553</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.388688</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.349721</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41 rows × 218 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfd0411b-77be-4b5d-97d3-c4224c323e53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bfd0411b-77be-4b5d-97d3-c4224c323e53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bfd0411b-77be-4b5d-97d3-c4224c323e53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "vectors = tfidf.fit_transform(n_X)\n",
        "features_name = tfidf.get_feature_names()\n",
        "text_vect = pd.DataFrame(vectors.todense(),columns=features_name)\n",
        "text_vect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64db348a",
      "metadata": {
        "id": "64db348a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Preparation"
      ],
      "metadata": {
        "id": "Oc61NkRHZFHU"
      },
      "id": "Oc61NkRHZFHU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "using tf.Variable will aggregate the vectorized value"
      ],
      "metadata": {
        "id": "hwHHF25pYvep"
      },
      "id": "hwHHF25pYvep"
    },
    {
      "cell_type": "code",
      "source": [
        "temp = tf.Variable(text_vect)"
      ],
      "metadata": {
        "id": "wfzRApmRVTvN"
      },
      "id": "wfzRApmRVTvN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(text_vect,y,train_size=0.75,test_size=0.25)"
      ],
      "metadata": {
        "id": "JYFoTkY2XuNC"
      },
      "id": "JYFoTkY2XuNC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iOKhcAQYh4U",
        "outputId": "f01a134c-f345-42ad-c0be-d44c76a68716"
      },
      "id": "1iOKhcAQYh4U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 218)\n",
            "(30,)\n",
            "(11, 218)\n",
            "(11,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Creation "
      ],
      "metadata": {
        "id": "Oi0ZBcnuZJEe"
      },
      "id": "Oi0ZBcnuZJEe"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from keras.layers import Dense,Activation"
      ],
      "metadata": {
        "id": "8YMM-brLYmlu"
      },
      "id": "8YMM-brLYmlu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with 5 hidden layer"
      ],
      "metadata": {
        "id": "g3yYNBQRgtlN"
      },
      "id": "g3yYNBQRgtlN"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu',input_dim=X_train.shape[1]))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(2, activation='sigmoid')) #output layer\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra0lv5C6ZUHu",
        "outputId": "2838315d-ce62-4c3e-b42d-719fd26d2ebc"
      },
      "id": "Ra0lv5C6ZUHu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               28032     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,050\n",
            "Trainable params: 39,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history=model.fit(X_train,y_train,epochs=100,verbose=2,validation_split=0.2,batch_size=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhexGguQZXXR",
        "outputId": "6de0b09d-8478-4872-cf0c-5d1c9f79ea60"
      },
      "id": "VhexGguQZXXR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 - 2s - loss: 0.6901 - accuracy: 0.5417 - val_loss: 0.6944 - val_accuracy: 0.3333 - 2s/epoch - 866ms/step\n",
            "Epoch 2/100\n",
            "2/2 - 0s - loss: 0.6783 - accuracy: 0.6667 - val_loss: 0.6935 - val_accuracy: 0.3333 - 40ms/epoch - 20ms/step\n",
            "Epoch 3/100\n",
            "2/2 - 0s - loss: 0.6687 - accuracy: 0.6667 - val_loss: 0.6953 - val_accuracy: 0.3333 - 40ms/epoch - 20ms/step\n",
            "Epoch 4/100\n",
            "2/2 - 0s - loss: 0.6578 - accuracy: 0.6667 - val_loss: 0.6981 - val_accuracy: 0.3333 - 39ms/epoch - 19ms/step\n",
            "Epoch 5/100\n",
            "2/2 - 0s - loss: 0.6483 - accuracy: 0.6667 - val_loss: 0.7036 - val_accuracy: 0.3333 - 41ms/epoch - 20ms/step\n",
            "Epoch 6/100\n",
            "2/2 - 0s - loss: 0.6335 - accuracy: 0.6667 - val_loss: 0.7102 - val_accuracy: 0.3333 - 50ms/epoch - 25ms/step\n",
            "Epoch 7/100\n",
            "2/2 - 0s - loss: 0.6166 - accuracy: 0.6667 - val_loss: 0.7190 - val_accuracy: 0.3333 - 41ms/epoch - 20ms/step\n",
            "Epoch 8/100\n",
            "2/2 - 0s - loss: 0.5979 - accuracy: 0.6667 - val_loss: 0.7295 - val_accuracy: 0.3333 - 42ms/epoch - 21ms/step\n",
            "Epoch 9/100\n",
            "2/2 - 0s - loss: 0.5758 - accuracy: 0.6667 - val_loss: 0.7406 - val_accuracy: 0.3333 - 38ms/epoch - 19ms/step\n",
            "Epoch 10/100\n",
            "2/2 - 0s - loss: 0.5497 - accuracy: 0.6667 - val_loss: 0.7528 - val_accuracy: 0.3333 - 42ms/epoch - 21ms/step\n",
            "Epoch 11/100\n",
            "2/2 - 0s - loss: 0.5204 - accuracy: 0.6667 - val_loss: 0.7673 - val_accuracy: 0.3333 - 39ms/epoch - 19ms/step\n",
            "Epoch 12/100\n",
            "2/2 - 0s - loss: 0.4884 - accuracy: 0.6667 - val_loss: 0.7880 - val_accuracy: 0.3333 - 59ms/epoch - 30ms/step\n",
            "Epoch 13/100\n",
            "2/2 - 0s - loss: 0.4540 - accuracy: 0.6667 - val_loss: 0.8204 - val_accuracy: 0.3333 - 43ms/epoch - 21ms/step\n",
            "Epoch 14/100\n",
            "2/2 - 0s - loss: 0.4171 - accuracy: 0.7083 - val_loss: 0.8655 - val_accuracy: 0.3333 - 39ms/epoch - 20ms/step\n",
            "Epoch 15/100\n",
            "2/2 - 0s - loss: 0.3850 - accuracy: 0.7083 - val_loss: 0.9177 - val_accuracy: 0.3333 - 37ms/epoch - 19ms/step\n",
            "Epoch 16/100\n",
            "2/2 - 0s - loss: 0.3517 - accuracy: 0.7083 - val_loss: 0.9663 - val_accuracy: 0.3333 - 42ms/epoch - 21ms/step\n",
            "Epoch 17/100\n",
            "2/2 - 0s - loss: 0.3214 - accuracy: 0.8333 - val_loss: 1.0273 - val_accuracy: 0.3333 - 40ms/epoch - 20ms/step\n",
            "Epoch 18/100\n",
            "2/2 - 0s - loss: 0.2911 - accuracy: 0.8333 - val_loss: 1.0932 - val_accuracy: 0.3333 - 41ms/epoch - 21ms/step\n",
            "Epoch 19/100\n",
            "2/2 - 0s - loss: 0.2611 - accuracy: 0.9167 - val_loss: 1.1498 - val_accuracy: 0.3333 - 42ms/epoch - 21ms/step\n",
            "Epoch 20/100\n",
            "2/2 - 0s - loss: 0.2298 - accuracy: 1.0000 - val_loss: 1.2043 - val_accuracy: 0.3333 - 47ms/epoch - 24ms/step\n",
            "Epoch 21/100\n",
            "2/2 - 0s - loss: 0.1962 - accuracy: 1.0000 - val_loss: 1.2343 - val_accuracy: 0.3333 - 49ms/epoch - 24ms/step\n",
            "Epoch 22/100\n",
            "2/2 - 0s - loss: 0.1691 - accuracy: 1.0000 - val_loss: 1.2313 - val_accuracy: 0.3333 - 39ms/epoch - 20ms/step\n",
            "Epoch 23/100\n",
            "2/2 - 0s - loss: 0.1419 - accuracy: 1.0000 - val_loss: 1.2113 - val_accuracy: 0.3333 - 29ms/epoch - 14ms/step\n",
            "Epoch 24/100\n",
            "2/2 - 0s - loss: 0.1191 - accuracy: 1.0000 - val_loss: 1.1518 - val_accuracy: 0.3333 - 29ms/epoch - 15ms/step\n",
            "Epoch 25/100\n",
            "2/2 - 0s - loss: 0.0995 - accuracy: 1.0000 - val_loss: 1.0806 - val_accuracy: 0.3333 - 26ms/epoch - 13ms/step\n",
            "Epoch 26/100\n",
            "2/2 - 0s - loss: 0.0807 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.3333 - 28ms/epoch - 14ms/step\n",
            "Epoch 27/100\n",
            "2/2 - 0s - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.9376 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 28/100\n",
            "2/2 - 0s - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.8684 - val_accuracy: 0.5000 - 31ms/epoch - 16ms/step\n",
            "Epoch 29/100\n",
            "2/2 - 0s - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.7939 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 30/100\n",
            "2/2 - 0s - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.7366 - val_accuracy: 0.6667 - 29ms/epoch - 14ms/step\n",
            "Epoch 31/100\n",
            "2/2 - 0s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.6667 - 27ms/epoch - 13ms/step\n",
            "Epoch 32/100\n",
            "2/2 - 0s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.6530 - val_accuracy: 0.6667 - 27ms/epoch - 13ms/step\n",
            "Epoch 33/100\n",
            "2/2 - 0s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.6262 - val_accuracy: 0.6667 - 36ms/epoch - 18ms/step\n",
            "Epoch 34/100\n",
            "2/2 - 0s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.6039 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 35/100\n",
            "2/2 - 0s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5870 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 36/100\n",
            "2/2 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.5756 - val_accuracy: 0.6667 - 31ms/epoch - 15ms/step\n",
            "Epoch 37/100\n",
            "2/2 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5666 - val_accuracy: 0.6667 - 46ms/epoch - 23ms/step\n",
            "Epoch 38/100\n",
            "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5611 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 39/100\n",
            "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5592 - val_accuracy: 0.6667 - 28ms/epoch - 14ms/step\n",
            "Epoch 40/100\n",
            "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.6667 - 28ms/epoch - 14ms/step\n",
            "Epoch 41/100\n",
            "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5596 - val_accuracy: 0.6667 - 31ms/epoch - 15ms/step\n",
            "Epoch 42/100\n",
            "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5624 - val_accuracy: 0.6667 - 26ms/epoch - 13ms/step\n",
            "Epoch 43/100\n",
            "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5650 - val_accuracy: 0.6667 - 34ms/epoch - 17ms/step\n",
            "Epoch 44/100\n",
            "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5676 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 45/100\n",
            "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5705 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 46/100\n",
            "2/2 - 0s - loss: 9.2518e-04 - accuracy: 1.0000 - val_loss: 0.5727 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 47/100\n",
            "2/2 - 0s - loss: 8.4552e-04 - accuracy: 1.0000 - val_loss: 0.5745 - val_accuracy: 0.6667 - 35ms/epoch - 17ms/step\n",
            "Epoch 48/100\n",
            "2/2 - 0s - loss: 7.8458e-04 - accuracy: 1.0000 - val_loss: 0.5762 - val_accuracy: 0.6667 - 54ms/epoch - 27ms/step\n",
            "Epoch 49/100\n",
            "2/2 - 0s - loss: 7.2142e-04 - accuracy: 1.0000 - val_loss: 0.5779 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 50/100\n",
            "2/2 - 0s - loss: 6.7868e-04 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 51/100\n",
            "2/2 - 0s - loss: 6.3949e-04 - accuracy: 1.0000 - val_loss: 0.5777 - val_accuracy: 0.6667 - 49ms/epoch - 25ms/step\n",
            "Epoch 52/100\n",
            "2/2 - 0s - loss: 6.0455e-04 - accuracy: 1.0000 - val_loss: 0.5766 - val_accuracy: 0.6667 - 31ms/epoch - 15ms/step\n",
            "Epoch 53/100\n",
            "2/2 - 0s - loss: 5.7431e-04 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.6667 - 29ms/epoch - 15ms/step\n",
            "Epoch 54/100\n",
            "2/2 - 0s - loss: 5.4763e-04 - accuracy: 1.0000 - val_loss: 0.5739 - val_accuracy: 0.6667 - 27ms/epoch - 13ms/step\n",
            "Epoch 55/100\n",
            "2/2 - 0s - loss: 5.2725e-04 - accuracy: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 56/100\n",
            "2/2 - 0s - loss: 5.0202e-04 - accuracy: 1.0000 - val_loss: 0.5714 - val_accuracy: 0.6667 - 31ms/epoch - 15ms/step\n",
            "Epoch 57/100\n",
            "2/2 - 0s - loss: 4.8408e-04 - accuracy: 1.0000 - val_loss: 0.5702 - val_accuracy: 0.6667 - 27ms/epoch - 13ms/step\n",
            "Epoch 58/100\n",
            "2/2 - 0s - loss: 4.6741e-04 - accuracy: 1.0000 - val_loss: 0.5691 - val_accuracy: 0.6667 - 33ms/epoch - 16ms/step\n",
            "Epoch 59/100\n",
            "2/2 - 0s - loss: 4.5034e-04 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.6667 - 29ms/epoch - 14ms/step\n",
            "Epoch 60/100\n",
            "2/2 - 0s - loss: 4.3678e-04 - accuracy: 1.0000 - val_loss: 0.5673 - val_accuracy: 0.6667 - 29ms/epoch - 14ms/step\n",
            "Epoch 61/100\n",
            "2/2 - 0s - loss: 4.2114e-04 - accuracy: 1.0000 - val_loss: 0.5666 - val_accuracy: 0.6667 - 28ms/epoch - 14ms/step\n",
            "Epoch 62/100\n",
            "2/2 - 0s - loss: 4.0836e-04 - accuracy: 1.0000 - val_loss: 0.5658 - val_accuracy: 0.6667 - 26ms/epoch - 13ms/step\n",
            "Epoch 63/100\n",
            "2/2 - 0s - loss: 3.9726e-04 - accuracy: 1.0000 - val_loss: 0.5649 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 64/100\n",
            "2/2 - 0s - loss: 3.8589e-04 - accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 0.6667 - 29ms/epoch - 15ms/step\n",
            "Epoch 65/100\n",
            "2/2 - 0s - loss: 3.7503e-04 - accuracy: 1.0000 - val_loss: 0.5629 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 66/100\n",
            "2/2 - 0s - loss: 3.6413e-04 - accuracy: 1.0000 - val_loss: 0.5620 - val_accuracy: 0.6667 - 29ms/epoch - 14ms/step\n",
            "Epoch 67/100\n",
            "2/2 - 0s - loss: 3.5493e-04 - accuracy: 1.0000 - val_loss: 0.5609 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 68/100\n",
            "2/2 - 0s - loss: 3.4482e-04 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.6667 - 29ms/epoch - 15ms/step\n",
            "Epoch 69/100\n",
            "2/2 - 0s - loss: 3.3508e-04 - accuracy: 1.0000 - val_loss: 0.5592 - val_accuracy: 0.6667 - 27ms/epoch - 13ms/step\n",
            "Epoch 70/100\n",
            "2/2 - 0s - loss: 3.2657e-04 - accuracy: 1.0000 - val_loss: 0.5581 - val_accuracy: 0.6667 - 29ms/epoch - 14ms/step\n",
            "Epoch 71/100\n",
            "2/2 - 0s - loss: 3.1824e-04 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.6667 - 26ms/epoch - 13ms/step\n",
            "Epoch 72/100\n",
            "2/2 - 0s - loss: 3.1075e-04 - accuracy: 1.0000 - val_loss: 0.5549 - val_accuracy: 0.6667 - 27ms/epoch - 13ms/step\n",
            "Epoch 73/100\n",
            "2/2 - 0s - loss: 3.0238e-04 - accuracy: 1.0000 - val_loss: 0.5534 - val_accuracy: 0.6667 - 27ms/epoch - 13ms/step\n",
            "Epoch 74/100\n",
            "2/2 - 0s - loss: 2.9562e-04 - accuracy: 1.0000 - val_loss: 0.5519 - val_accuracy: 0.6667 - 25ms/epoch - 13ms/step\n",
            "Epoch 75/100\n",
            "2/2 - 0s - loss: 2.8772e-04 - accuracy: 1.0000 - val_loss: 0.5508 - val_accuracy: 0.6667 - 29ms/epoch - 15ms/step\n",
            "Epoch 76/100\n",
            "2/2 - 0s - loss: 2.8057e-04 - accuracy: 1.0000 - val_loss: 0.5498 - val_accuracy: 0.6667 - 27ms/epoch - 14ms/step\n",
            "Epoch 77/100\n",
            "2/2 - 0s - loss: 2.7411e-04 - accuracy: 1.0000 - val_loss: 0.5489 - val_accuracy: 0.6667 - 37ms/epoch - 18ms/step\n",
            "Epoch 78/100\n",
            "2/2 - 0s - loss: 2.6752e-04 - accuracy: 1.0000 - val_loss: 0.5482 - val_accuracy: 0.6667 - 29ms/epoch - 14ms/step\n",
            "Epoch 79/100\n",
            "2/2 - 0s - loss: 2.6209e-04 - accuracy: 1.0000 - val_loss: 0.5475 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 80/100\n",
            "2/2 - 0s - loss: 2.5599e-04 - accuracy: 1.0000 - val_loss: 0.5470 - val_accuracy: 0.6667 - 38ms/epoch - 19ms/step\n",
            "Epoch 81/100\n",
            "2/2 - 0s - loss: 2.4989e-04 - accuracy: 1.0000 - val_loss: 0.5465 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 82/100\n",
            "2/2 - 0s - loss: 2.4454e-04 - accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.6667 - 28ms/epoch - 14ms/step\n",
            "Epoch 83/100\n",
            "2/2 - 0s - loss: 2.3987e-04 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.6667 - 29ms/epoch - 14ms/step\n",
            "Epoch 84/100\n",
            "2/2 - 0s - loss: 2.3418e-04 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.6667 - 28ms/epoch - 14ms/step\n",
            "Epoch 85/100\n",
            "2/2 - 0s - loss: 2.2916e-04 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.6667 - 33ms/epoch - 17ms/step\n",
            "Epoch 86/100\n",
            "2/2 - 0s - loss: 2.2457e-04 - accuracy: 1.0000 - val_loss: 0.5440 - val_accuracy: 0.6667 - 28ms/epoch - 14ms/step\n",
            "Epoch 87/100\n",
            "2/2 - 0s - loss: 2.2011e-04 - accuracy: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.6667 - 28ms/epoch - 14ms/step\n",
            "Epoch 88/100\n",
            "2/2 - 0s - loss: 2.1569e-04 - accuracy: 1.0000 - val_loss: 0.5427 - val_accuracy: 0.6667 - 25ms/epoch - 13ms/step\n",
            "Epoch 89/100\n",
            "2/2 - 0s - loss: 2.1101e-04 - accuracy: 1.0000 - val_loss: 0.5421 - val_accuracy: 0.6667 - 29ms/epoch - 14ms/step\n",
            "Epoch 90/100\n",
            "2/2 - 0s - loss: 2.0693e-04 - accuracy: 1.0000 - val_loss: 0.5414 - val_accuracy: 0.6667 - 29ms/epoch - 14ms/step\n",
            "Epoch 91/100\n",
            "2/2 - 0s - loss: 2.0258e-04 - accuracy: 1.0000 - val_loss: 0.5409 - val_accuracy: 0.6667 - 27ms/epoch - 14ms/step\n",
            "Epoch 92/100\n",
            "2/2 - 0s - loss: 1.9845e-04 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.6667 - 34ms/epoch - 17ms/step\n",
            "Epoch 93/100\n",
            "2/2 - 0s - loss: 1.9488e-04 - accuracy: 1.0000 - val_loss: 0.5397 - val_accuracy: 0.6667 - 27ms/epoch - 13ms/step\n",
            "Epoch 94/100\n",
            "2/2 - 0s - loss: 1.9093e-04 - accuracy: 1.0000 - val_loss: 0.5391 - val_accuracy: 0.6667 - 36ms/epoch - 18ms/step\n",
            "Epoch 95/100\n",
            "2/2 - 0s - loss: 1.8742e-04 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 96/100\n",
            "2/2 - 0s - loss: 1.8410e-04 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.5000 - 39ms/epoch - 19ms/step\n",
            "Epoch 97/100\n",
            "2/2 - 0s - loss: 1.8058e-04 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 98/100\n",
            "2/2 - 0s - loss: 1.7694e-04 - accuracy: 1.0000 - val_loss: 0.5371 - val_accuracy: 0.5000 - 29ms/epoch - 14ms/step\n",
            "Epoch 99/100\n",
            "2/2 - 0s - loss: 1.7392e-04 - accuracy: 1.0000 - val_loss: 0.5368 - val_accuracy: 0.5000 - 29ms/epoch - 14ms/step\n",
            "Epoch 100/100\n",
            "2/2 - 0s - loss: 1.7081e-04 - accuracy: 1.0000 - val_loss: 0.5366 - val_accuracy: 0.5000 - 29ms/epoch - 14ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT_NtgCrZhyB",
        "outputId": "6ec52d57-832b-4de3-a78f-4857150dcf45"
      },
      "id": "gT_NtgCrZhyB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2000 - accuracy: 0.3636\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.2000417709350586, 0.3636363744735718]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "lr-geSEjerT5",
        "outputId": "e0ae7c97-e9ff-46fd-83c8-96161f3ecff9"
      },
      "id": "lr-geSEjerT5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model with 3 hidden layer"
      ],
      "metadata": {
        "id": "C80aGsGlgy7F"
      },
      "id": "C80aGsGlgy7F"
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(512, activation='relu',input_dim=X_train.shape[1]))\n",
        "model2.add(Dense(256, activation='relu'))\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dense(2, activation='sigmoid'))\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbohUWCDevyI",
        "outputId": "f269d069-b9c8-4184-ed6f-d0b85d6e9bb0"
      },
      "id": "sbohUWCDevyI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 512)               112128    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 284,738\n",
            "Trainable params: 284,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history=model2.fit(X_train,y_train,epochs=100,verbose=2,validation_split=0.2,batch_size=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V6TURpxfXcy",
        "outputId": "bb870777-4f5b-49e7-8a38-decb92370edb"
      },
      "id": "4V6TURpxfXcy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 - 1s - loss: 0.6880 - accuracy: 0.7083 - val_loss: 0.7098 - val_accuracy: 0.3333 - 615ms/epoch - 307ms/step\n",
            "Epoch 2/100\n",
            "2/2 - 0s - loss: 0.6374 - accuracy: 0.6667 - val_loss: 0.7374 - val_accuracy: 0.3333 - 30ms/epoch - 15ms/step\n",
            "Epoch 3/100\n",
            "2/2 - 0s - loss: 0.5789 - accuracy: 0.6667 - val_loss: 0.7761 - val_accuracy: 0.3333 - 34ms/epoch - 17ms/step\n",
            "Epoch 4/100\n",
            "2/2 - 0s - loss: 0.5165 - accuracy: 0.6667 - val_loss: 0.8318 - val_accuracy: 0.3333 - 31ms/epoch - 15ms/step\n",
            "Epoch 5/100\n",
            "2/2 - 0s - loss: 0.4344 - accuracy: 0.7500 - val_loss: 0.8910 - val_accuracy: 0.3333 - 36ms/epoch - 18ms/step\n",
            "Epoch 6/100\n",
            "2/2 - 0s - loss: 0.3535 - accuracy: 0.8750 - val_loss: 0.9801 - val_accuracy: 0.3333 - 34ms/epoch - 17ms/step\n",
            "Epoch 7/100\n",
            "2/2 - 0s - loss: 0.2748 - accuracy: 1.0000 - val_loss: 1.0873 - val_accuracy: 0.3333 - 30ms/epoch - 15ms/step\n",
            "Epoch 8/100\n",
            "2/2 - 0s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.1689 - val_accuracy: 0.3333 - 32ms/epoch - 16ms/step\n",
            "Epoch 9/100\n",
            "2/2 - 0s - loss: 0.1623 - accuracy: 1.0000 - val_loss: 1.2440 - val_accuracy: 0.3333 - 33ms/epoch - 16ms/step\n",
            "Epoch 10/100\n",
            "2/2 - 0s - loss: 0.1173 - accuracy: 1.0000 - val_loss: 1.2790 - val_accuracy: 0.3333 - 32ms/epoch - 16ms/step\n",
            "Epoch 11/100\n",
            "2/2 - 0s - loss: 0.0802 - accuracy: 1.0000 - val_loss: 1.2346 - val_accuracy: 0.3333 - 31ms/epoch - 15ms/step\n",
            "Epoch 12/100\n",
            "2/2 - 0s - loss: 0.0435 - accuracy: 1.0000 - val_loss: 1.1041 - val_accuracy: 0.3333 - 37ms/epoch - 18ms/step\n",
            "Epoch 13/100\n",
            "2/2 - 0s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.9168 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 14/100\n",
            "2/2 - 0s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.5000 - 31ms/epoch - 15ms/step\n",
            "Epoch 15/100\n",
            "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5825 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 16/100\n",
            "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.8333 - 32ms/epoch - 16ms/step\n",
            "Epoch 17/100\n",
            "2/2 - 0s - loss: 5.0095e-04 - accuracy: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.6667 - 36ms/epoch - 18ms/step\n",
            "Epoch 18/100\n",
            "2/2 - 0s - loss: 2.9399e-04 - accuracy: 1.0000 - val_loss: 0.5188 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 19/100\n",
            "2/2 - 0s - loss: 2.1323e-04 - accuracy: 1.0000 - val_loss: 0.5559 - val_accuracy: 0.6667 - 39ms/epoch - 20ms/step\n",
            "Epoch 20/100\n",
            "2/2 - 0s - loss: 1.7270e-04 - accuracy: 1.0000 - val_loss: 0.5947 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 21/100\n",
            "2/2 - 0s - loss: 1.3945e-04 - accuracy: 1.0000 - val_loss: 0.6263 - val_accuracy: 0.6667 - 35ms/epoch - 17ms/step\n",
            "Epoch 22/100\n",
            "2/2 - 0s - loss: 1.0920e-04 - accuracy: 1.0000 - val_loss: 0.6490 - val_accuracy: 0.6667 - 35ms/epoch - 18ms/step\n",
            "Epoch 23/100\n",
            "2/2 - 0s - loss: 8.4436e-05 - accuracy: 1.0000 - val_loss: 0.6623 - val_accuracy: 0.6667 - 38ms/epoch - 19ms/step\n",
            "Epoch 24/100\n",
            "2/2 - 0s - loss: 6.4110e-05 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 25/100\n",
            "2/2 - 0s - loss: 5.0656e-05 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 0.6667 - 31ms/epoch - 15ms/step\n",
            "Epoch 26/100\n",
            "2/2 - 0s - loss: 3.7932e-05 - accuracy: 1.0000 - val_loss: 0.6626 - val_accuracy: 0.6667 - 34ms/epoch - 17ms/step\n",
            "Epoch 27/100\n",
            "2/2 - 0s - loss: 2.9374e-05 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 28/100\n",
            "2/2 - 0s - loss: 2.3692e-05 - accuracy: 1.0000 - val_loss: 0.6471 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 29/100\n",
            "2/2 - 0s - loss: 1.9237e-05 - accuracy: 1.0000 - val_loss: 0.6375 - val_accuracy: 0.6667 - 33ms/epoch - 17ms/step\n",
            "Epoch 30/100\n",
            "2/2 - 0s - loss: 1.5512e-05 - accuracy: 1.0000 - val_loss: 0.6277 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 31/100\n",
            "2/2 - 0s - loss: 1.3093e-05 - accuracy: 1.0000 - val_loss: 0.6179 - val_accuracy: 0.6667 - 31ms/epoch - 15ms/step\n",
            "Epoch 32/100\n",
            "2/2 - 0s - loss: 1.1285e-05 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 33/100\n",
            "2/2 - 0s - loss: 9.6658e-06 - accuracy: 1.0000 - val_loss: 0.5995 - val_accuracy: 0.6667 - 34ms/epoch - 17ms/step\n",
            "Epoch 34/100\n",
            "2/2 - 0s - loss: 8.6178e-06 - accuracy: 1.0000 - val_loss: 0.5911 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 35/100\n",
            "2/2 - 0s - loss: 7.7833e-06 - accuracy: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.6667 - 33ms/epoch - 16ms/step\n",
            "Epoch 36/100\n",
            "2/2 - 0s - loss: 6.9389e-06 - accuracy: 1.0000 - val_loss: 0.5764 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 37/100\n",
            "2/2 - 0s - loss: 6.4323e-06 - accuracy: 1.0000 - val_loss: 0.5698 - val_accuracy: 0.6667 - 34ms/epoch - 17ms/step\n",
            "Epoch 38/100\n",
            "2/2 - 0s - loss: 5.9108e-06 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 39/100\n",
            "2/2 - 0s - loss: 5.5035e-06 - accuracy: 1.0000 - val_loss: 0.5585 - val_accuracy: 0.6667 - 31ms/epoch - 15ms/step\n",
            "Epoch 40/100\n",
            "2/2 - 0s - loss: 5.1707e-06 - accuracy: 1.0000 - val_loss: 0.5534 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 41/100\n",
            "2/2 - 0s - loss: 4.8826e-06 - accuracy: 1.0000 - val_loss: 0.5488 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 42/100\n",
            "2/2 - 0s - loss: 4.6442e-06 - accuracy: 1.0000 - val_loss: 0.5444 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 43/100\n",
            "2/2 - 0s - loss: 4.4356e-06 - accuracy: 1.0000 - val_loss: 0.5404 - val_accuracy: 0.6667 - 35ms/epoch - 18ms/step\n",
            "Epoch 44/100\n",
            "2/2 - 0s - loss: 4.2567e-06 - accuracy: 1.0000 - val_loss: 0.5366 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 45/100\n",
            "2/2 - 0s - loss: 4.0779e-06 - accuracy: 1.0000 - val_loss: 0.5331 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 46/100\n",
            "2/2 - 0s - loss: 3.9389e-06 - accuracy: 1.0000 - val_loss: 0.5299 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 47/100\n",
            "2/2 - 0s - loss: 3.7849e-06 - accuracy: 1.0000 - val_loss: 0.5268 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 48/100\n",
            "2/2 - 0s - loss: 3.6855e-06 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.6667 - 34ms/epoch - 17ms/step\n",
            "Epoch 49/100\n",
            "2/2 - 0s - loss: 3.5713e-06 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.6667 - 33ms/epoch - 16ms/step\n",
            "Epoch 50/100\n",
            "2/2 - 0s - loss: 3.4471e-06 - accuracy: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.6667 - 40ms/epoch - 20ms/step\n",
            "Epoch 51/100\n",
            "2/2 - 0s - loss: 3.3776e-06 - accuracy: 1.0000 - val_loss: 0.5163 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 52/100\n",
            "2/2 - 0s - loss: 3.2782e-06 - accuracy: 1.0000 - val_loss: 0.5140 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 53/100\n",
            "2/2 - 0s - loss: 3.1988e-06 - accuracy: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.6667 - 35ms/epoch - 17ms/step\n",
            "Epoch 54/100\n",
            "2/2 - 0s - loss: 3.1193e-06 - accuracy: 1.0000 - val_loss: 0.5096 - val_accuracy: 0.6667 - 30ms/epoch - 15ms/step\n",
            "Epoch 55/100\n",
            "2/2 - 0s - loss: 3.0398e-06 - accuracy: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.6667 - 31ms/epoch - 15ms/step\n",
            "Epoch 56/100\n",
            "2/2 - 0s - loss: 2.9753e-06 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.6667 - 36ms/epoch - 18ms/step\n",
            "Epoch 57/100\n",
            "2/2 - 0s - loss: 2.9256e-06 - accuracy: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 58/100\n",
            "2/2 - 0s - loss: 2.8560e-06 - accuracy: 1.0000 - val_loss: 0.5017 - val_accuracy: 0.6667 - 31ms/epoch - 15ms/step\n",
            "Epoch 59/100\n",
            "2/2 - 0s - loss: 2.8014e-06 - accuracy: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 60/100\n",
            "2/2 - 0s - loss: 2.7368e-06 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.6667 - 41ms/epoch - 21ms/step\n",
            "Epoch 61/100\n",
            "2/2 - 0s - loss: 2.6971e-06 - accuracy: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 62/100\n",
            "2/2 - 0s - loss: 2.6425e-06 - accuracy: 1.0000 - val_loss: 0.4949 - val_accuracy: 0.6667 - 35ms/epoch - 18ms/step\n",
            "Epoch 63/100\n",
            "2/2 - 0s - loss: 2.5928e-06 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.6667 - 33ms/epoch - 17ms/step\n",
            "Epoch 64/100\n",
            "2/2 - 0s - loss: 2.5332e-06 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 65/100\n",
            "2/2 - 0s - loss: 2.4984e-06 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.6667 - 35ms/epoch - 18ms/step\n",
            "Epoch 66/100\n",
            "2/2 - 0s - loss: 2.4537e-06 - accuracy: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.6667 - 36ms/epoch - 18ms/step\n",
            "Epoch 67/100\n",
            "2/2 - 0s - loss: 2.4090e-06 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.6667 - 36ms/epoch - 18ms/step\n",
            "Epoch 68/100\n",
            "2/2 - 0s - loss: 2.3792e-06 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.6667 - 34ms/epoch - 17ms/step\n",
            "Epoch 69/100\n",
            "2/2 - 0s - loss: 2.3295e-06 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.6667 - 43ms/epoch - 21ms/step\n",
            "Epoch 70/100\n",
            "2/2 - 0s - loss: 2.2948e-06 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.6667 - 33ms/epoch - 16ms/step\n",
            "Epoch 71/100\n",
            "2/2 - 0s - loss: 2.2699e-06 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.6667 - 33ms/epoch - 17ms/step\n",
            "Epoch 72/100\n",
            "2/2 - 0s - loss: 2.2302e-06 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.6667 - 33ms/epoch - 16ms/step\n",
            "Epoch 73/100\n",
            "2/2 - 0s - loss: 2.1954e-06 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 74/100\n",
            "2/2 - 0s - loss: 2.1607e-06 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 75/100\n",
            "2/2 - 0s - loss: 2.1160e-06 - accuracy: 1.0000 - val_loss: 0.4771 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 76/100\n",
            "2/2 - 0s - loss: 2.0911e-06 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.6667 - 46ms/epoch - 23ms/step\n",
            "Epoch 77/100\n",
            "2/2 - 0s - loss: 2.0564e-06 - accuracy: 1.0000 - val_loss: 0.4748 - val_accuracy: 0.6667 - 34ms/epoch - 17ms/step\n",
            "Epoch 78/100\n",
            "2/2 - 0s - loss: 2.0365e-06 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 79/100\n",
            "2/2 - 0s - loss: 2.0117e-06 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.6667 - 35ms/epoch - 18ms/step\n",
            "Epoch 80/100\n",
            "2/2 - 0s - loss: 1.9719e-06 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.6667 - 31ms/epoch - 15ms/step\n",
            "Epoch 81/100\n",
            "2/2 - 0s - loss: 1.9520e-06 - accuracy: 1.0000 - val_loss: 0.4706 - val_accuracy: 0.6667 - 35ms/epoch - 17ms/step\n",
            "Epoch 82/100\n",
            "2/2 - 0s - loss: 1.9272e-06 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.6667 - 37ms/epoch - 18ms/step\n",
            "Epoch 83/100\n",
            "2/2 - 0s - loss: 1.8924e-06 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.6667 - 33ms/epoch - 16ms/step\n",
            "Epoch 84/100\n",
            "2/2 - 0s - loss: 1.8676e-06 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.6667 - 38ms/epoch - 19ms/step\n",
            "Epoch 85/100\n",
            "2/2 - 0s - loss: 1.8477e-06 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.6667 - 34ms/epoch - 17ms/step\n",
            "Epoch 86/100\n",
            "2/2 - 0s - loss: 1.8229e-06 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.6667 - 51ms/epoch - 25ms/step\n",
            "Epoch 87/100\n",
            "2/2 - 0s - loss: 1.7981e-06 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 88/100\n",
            "2/2 - 0s - loss: 1.7782e-06 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n",
            "Epoch 89/100\n",
            "2/2 - 0s - loss: 1.7434e-06 - accuracy: 1.0000 - val_loss: 0.4630 - val_accuracy: 0.6667 - 34ms/epoch - 17ms/step\n",
            "Epoch 90/100\n",
            "2/2 - 0s - loss: 1.7285e-06 - accuracy: 1.0000 - val_loss: 0.4622 - val_accuracy: 0.6667 - 46ms/epoch - 23ms/step\n",
            "Epoch 91/100\n",
            "2/2 - 0s - loss: 1.7087e-06 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 92/100\n",
            "2/2 - 0s - loss: 1.6938e-06 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.6667 - 33ms/epoch - 16ms/step\n",
            "Epoch 93/100\n",
            "2/2 - 0s - loss: 1.6689e-06 - accuracy: 1.0000 - val_loss: 0.4598 - val_accuracy: 0.6667 - 34ms/epoch - 17ms/step\n",
            "Epoch 94/100\n",
            "2/2 - 0s - loss: 1.6540e-06 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.6667 - 37ms/epoch - 19ms/step\n",
            "Epoch 95/100\n",
            "2/2 - 0s - loss: 1.6342e-06 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.6667 - 37ms/epoch - 18ms/step\n",
            "Epoch 96/100\n",
            "2/2 - 0s - loss: 1.6044e-06 - accuracy: 1.0000 - val_loss: 0.4575 - val_accuracy: 0.6667 - 36ms/epoch - 18ms/step\n",
            "Epoch 97/100\n",
            "2/2 - 0s - loss: 1.5845e-06 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.6667 - 59ms/epoch - 30ms/step\n",
            "Epoch 98/100\n",
            "2/2 - 0s - loss: 1.5597e-06 - accuracy: 1.0000 - val_loss: 0.4561 - val_accuracy: 0.6667 - 33ms/epoch - 16ms/step\n",
            "Epoch 99/100\n",
            "2/2 - 0s - loss: 1.5497e-06 - accuracy: 1.0000 - val_loss: 0.4554 - val_accuracy: 0.6667 - 32ms/epoch - 16ms/step\n",
            "Epoch 100/100\n",
            "2/2 - 0s - loss: 1.5448e-06 - accuracy: 1.0000 - val_loss: 0.4547 - val_accuracy: 0.6667 - 31ms/epoch - 16ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNwOfEWhfh-x",
        "outputId": "4865cec4-ed2d-43f4-b3d9-56fbf8fcc4e5"
      },
      "id": "vNwOfEWhfh-x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 1.4835 - accuracy: 0.2727\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4834818840026855, 0.27272728085517883]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "E3jfU2XOf1A-",
        "outputId": "6977e554-1cc8-440c-db96-32d312b92061"
      },
      "id": "E3jfU2XOf1A-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with two hidden layer"
      ],
      "metadata": {
        "id": "HkXsrx8IhlbM"
      },
      "id": "HkXsrx8IhlbM"
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Dense(1028, activation='relu',input_dim=X_train.shape[1]))\n",
        "model3.add(Dense(512, activation='relu'))\n",
        "model3.add(Dense(256, activation='relu'))\n",
        "model3.add(Dense(2, activation='sigmoid')) #output layer\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5mTsJE0f3xP",
        "outputId": "37953f27-2247-4542-b44c-880008c97bfd"
      },
      "id": "F5mTsJE0f3xP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 1028)              225132    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 512)               526848    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 883,822\n",
            "Trainable params: 883,822\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history=model3.fit(X_train,y_train,epochs=100,verbose=2,validation_split=0.2,batch_size=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a14nUsoWhoIN",
        "outputId": "651588b1-0933-43d7-f504-b12a91d98082"
      },
      "id": "a14nUsoWhoIN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 - 2s - loss: 0.6881 - accuracy: 0.5833 - val_loss: 0.7414 - val_accuracy: 0.3333 - 2s/epoch - 823ms/step\n",
            "Epoch 2/100\n",
            "2/2 - 0s - loss: 0.5861 - accuracy: 0.6667 - val_loss: 0.8015 - val_accuracy: 0.3333 - 64ms/epoch - 32ms/step\n",
            "Epoch 3/100\n",
            "2/2 - 0s - loss: 0.4865 - accuracy: 0.6667 - val_loss: 0.8930 - val_accuracy: 0.3333 - 59ms/epoch - 30ms/step\n",
            "Epoch 4/100\n",
            "2/2 - 0s - loss: 0.3695 - accuracy: 0.7917 - val_loss: 0.9841 - val_accuracy: 0.3333 - 64ms/epoch - 32ms/step\n",
            "Epoch 5/100\n",
            "2/2 - 0s - loss: 0.2501 - accuracy: 1.0000 - val_loss: 1.0362 - val_accuracy: 0.3333 - 76ms/epoch - 38ms/step\n",
            "Epoch 6/100\n",
            "2/2 - 0s - loss: 0.1509 - accuracy: 1.0000 - val_loss: 1.0973 - val_accuracy: 0.3333 - 59ms/epoch - 29ms/step\n",
            "Epoch 7/100\n",
            "2/2 - 0s - loss: 0.0832 - accuracy: 1.0000 - val_loss: 1.1193 - val_accuracy: 0.3333 - 61ms/epoch - 31ms/step\n",
            "Epoch 8/100\n",
            "2/2 - 0s - loss: 0.0420 - accuracy: 1.0000 - val_loss: 1.0498 - val_accuracy: 0.3333 - 65ms/epoch - 33ms/step\n",
            "Epoch 9/100\n",
            "2/2 - 0s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.9201 - val_accuracy: 0.5000 - 112ms/epoch - 56ms/step\n",
            "Epoch 10/100\n",
            "2/2 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7806 - val_accuracy: 0.6667 - 70ms/epoch - 35ms/step\n",
            "Epoch 11/100\n",
            "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6638 - val_accuracy: 0.6667 - 64ms/epoch - 32ms/step\n",
            "Epoch 12/100\n",
            "2/2 - 0s - loss: 3.2042e-04 - accuracy: 1.0000 - val_loss: 0.5832 - val_accuracy: 0.5000 - 76ms/epoch - 38ms/step\n",
            "Epoch 13/100\n",
            "2/2 - 0s - loss: 1.0135e-04 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.5000 - 64ms/epoch - 32ms/step\n",
            "Epoch 14/100\n",
            "2/2 - 0s - loss: 3.3968e-05 - accuracy: 1.0000 - val_loss: 0.5153 - val_accuracy: 0.6667 - 109ms/epoch - 54ms/step\n",
            "Epoch 15/100\n",
            "2/2 - 0s - loss: 1.4484e-05 - accuracy: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.6667 - 59ms/epoch - 29ms/step\n",
            "Epoch 16/100\n",
            "2/2 - 0s - loss: 6.9240e-06 - accuracy: 1.0000 - val_loss: 0.5193 - val_accuracy: 0.8333 - 73ms/epoch - 37ms/step\n",
            "Epoch 17/100\n",
            "2/2 - 0s - loss: 3.9885e-06 - accuracy: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.8333 - 88ms/epoch - 44ms/step\n",
            "Epoch 18/100\n",
            "2/2 - 0s - loss: 2.6077e-06 - accuracy: 1.0000 - val_loss: 0.5512 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
            "Epoch 19/100\n",
            "2/2 - 0s - loss: 1.8477e-06 - accuracy: 1.0000 - val_loss: 0.5697 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
            "Epoch 20/100\n",
            "2/2 - 0s - loss: 1.4504e-06 - accuracy: 1.0000 - val_loss: 0.5879 - val_accuracy: 0.8333 - 61ms/epoch - 31ms/step\n",
            "Epoch 21/100\n",
            "2/2 - 0s - loss: 1.1673e-06 - accuracy: 1.0000 - val_loss: 0.6048 - val_accuracy: 0.8333 - 57ms/epoch - 28ms/step\n",
            "Epoch 22/100\n",
            "2/2 - 0s - loss: 9.8844e-07 - accuracy: 1.0000 - val_loss: 0.6203 - val_accuracy: 0.8333 - 61ms/epoch - 30ms/step\n",
            "Epoch 23/100\n",
            "2/2 - 0s - loss: 8.4936e-07 - accuracy: 1.0000 - val_loss: 0.6339 - val_accuracy: 0.8333 - 59ms/epoch - 29ms/step\n",
            "Epoch 24/100\n",
            "2/2 - 0s - loss: 7.7983e-07 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 0.8333 - 66ms/epoch - 33ms/step\n",
            "Epoch 25/100\n",
            "2/2 - 0s - loss: 6.9539e-07 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
            "Epoch 26/100\n",
            "2/2 - 0s - loss: 6.4075e-07 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 0.8333 - 63ms/epoch - 31ms/step\n",
            "Epoch 27/100\n",
            "2/2 - 0s - loss: 5.9108e-07 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.8333 - 55ms/epoch - 28ms/step\n",
            "Epoch 28/100\n",
            "2/2 - 0s - loss: 5.7121e-07 - accuracy: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
            "Epoch 29/100\n",
            "2/2 - 0s - loss: 5.4638e-07 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8333 - 91ms/epoch - 46ms/step\n",
            "Epoch 30/100\n",
            "2/2 - 0s - loss: 5.1657e-07 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8333 - 165ms/epoch - 82ms/step\n",
            "Epoch 31/100\n",
            "2/2 - 0s - loss: 5.0167e-07 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.8333 - 125ms/epoch - 63ms/step\n",
            "Epoch 32/100\n",
            "2/2 - 0s - loss: 4.9174e-07 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8333 - 133ms/epoch - 67ms/step\n",
            "Epoch 33/100\n",
            "2/2 - 0s - loss: 4.8180e-07 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8333 - 153ms/epoch - 76ms/step\n",
            "Epoch 34/100\n",
            "2/2 - 0s - loss: 4.6690e-07 - accuracy: 1.0000 - val_loss: 0.6973 - val_accuracy: 0.8333 - 150ms/epoch - 75ms/step\n",
            "Epoch 35/100\n",
            "2/2 - 0s - loss: 4.6194e-07 - accuracy: 1.0000 - val_loss: 0.6987 - val_accuracy: 0.8333 - 120ms/epoch - 60ms/step\n",
            "Epoch 36/100\n",
            "2/2 - 0s - loss: 4.5200e-07 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8333 - 89ms/epoch - 44ms/step\n",
            "Epoch 37/100\n",
            "2/2 - 0s - loss: 4.4703e-07 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.8333 - 120ms/epoch - 60ms/step\n",
            "Epoch 38/100\n",
            "2/2 - 0s - loss: 4.3710e-07 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.8333 - 117ms/epoch - 59ms/step\n",
            "Epoch 39/100\n",
            "2/2 - 0s - loss: 4.2717e-07 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.8333 - 68ms/epoch - 34ms/step\n",
            "Epoch 40/100\n",
            "2/2 - 0s - loss: 4.1227e-07 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.8333 - 55ms/epoch - 27ms/step\n",
            "Epoch 41/100\n",
            "2/2 - 0s - loss: 4.0730e-07 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8333 - 57ms/epoch - 29ms/step\n",
            "Epoch 42/100\n",
            "2/2 - 0s - loss: 4.0233e-07 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8333 - 64ms/epoch - 32ms/step\n",
            "Epoch 43/100\n",
            "2/2 - 0s - loss: 3.9240e-07 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
            "Epoch 44/100\n",
            "2/2 - 0s - loss: 3.8743e-07 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8333 - 61ms/epoch - 30ms/step\n",
            "Epoch 45/100\n",
            "2/2 - 0s - loss: 3.8743e-07 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
            "Epoch 46/100\n",
            "2/2 - 0s - loss: 3.8743e-07 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8333 - 57ms/epoch - 29ms/step\n",
            "Epoch 47/100\n",
            "2/2 - 0s - loss: 3.8246e-07 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
            "Epoch 48/100\n",
            "2/2 - 0s - loss: 3.8246e-07 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.8333 - 67ms/epoch - 34ms/step\n",
            "Epoch 49/100\n",
            "2/2 - 0s - loss: 3.8246e-07 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
            "Epoch 50/100\n",
            "2/2 - 0s - loss: 3.7253e-07 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
            "Epoch 51/100\n",
            "2/2 - 0s - loss: 3.7253e-07 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.8333 - 55ms/epoch - 28ms/step\n",
            "Epoch 52/100\n",
            "2/2 - 0s - loss: 3.7253e-07 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8333 - 59ms/epoch - 30ms/step\n",
            "Epoch 53/100\n",
            "2/2 - 0s - loss: 3.6756e-07 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8333 - 71ms/epoch - 35ms/step\n",
            "Epoch 54/100\n",
            "2/2 - 0s - loss: 3.6756e-07 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8333 - 61ms/epoch - 31ms/step\n",
            "Epoch 55/100\n",
            "2/2 - 0s - loss: 3.6756e-07 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.8333 - 61ms/epoch - 31ms/step\n",
            "Epoch 56/100\n",
            "2/2 - 0s - loss: 3.6756e-07 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
            "Epoch 57/100\n",
            "2/2 - 0s - loss: 3.5763e-07 - accuracy: 1.0000 - val_loss: 0.6979 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
            "Epoch 58/100\n",
            "2/2 - 0s - loss: 3.5763e-07 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
            "Epoch 59/100\n",
            "2/2 - 0s - loss: 3.5763e-07 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.8333 - 59ms/epoch - 29ms/step\n",
            "Epoch 60/100\n",
            "2/2 - 0s - loss: 3.5266e-07 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
            "Epoch 61/100\n",
            "2/2 - 0s - loss: 3.4769e-07 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8333 - 63ms/epoch - 32ms/step\n",
            "Epoch 62/100\n",
            "2/2 - 0s - loss: 3.4769e-07 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.8333 - 68ms/epoch - 34ms/step\n",
            "Epoch 63/100\n",
            "2/2 - 0s - loss: 3.4273e-07 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8333 - 67ms/epoch - 33ms/step\n",
            "Epoch 64/100\n",
            "2/2 - 0s - loss: 3.3279e-07 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8333 - 68ms/epoch - 34ms/step\n",
            "Epoch 65/100\n",
            "2/2 - 0s - loss: 3.2783e-07 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
            "Epoch 66/100\n",
            "2/2 - 0s - loss: 3.2783e-07 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8333 - 67ms/epoch - 34ms/step\n",
            "Epoch 67/100\n",
            "2/2 - 0s - loss: 3.2783e-07 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.8333 - 61ms/epoch - 30ms/step\n",
            "Epoch 68/100\n",
            "2/2 - 0s - loss: 3.1789e-07 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8333 - 72ms/epoch - 36ms/step\n",
            "Epoch 69/100\n",
            "2/2 - 0s - loss: 3.1789e-07 - accuracy: 1.0000 - val_loss: 0.6933 - val_accuracy: 0.8333 - 59ms/epoch - 29ms/step\n",
            "Epoch 70/100\n",
            "2/2 - 0s - loss: 3.1789e-07 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8333 - 64ms/epoch - 32ms/step\n",
            "Epoch 71/100\n",
            "2/2 - 0s - loss: 3.1789e-07 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.8333 - 57ms/epoch - 29ms/step\n",
            "Epoch 72/100\n",
            "2/2 - 0s - loss: 3.1292e-07 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
            "Epoch 73/100\n",
            "2/2 - 0s - loss: 3.0796e-07 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.8333 - 57ms/epoch - 28ms/step\n",
            "Epoch 74/100\n",
            "2/2 - 0s - loss: 2.9306e-07 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
            "Epoch 75/100\n",
            "2/2 - 0s - loss: 2.9306e-07 - accuracy: 1.0000 - val_loss: 0.6910 - val_accuracy: 0.8333 - 74ms/epoch - 37ms/step\n",
            "Epoch 76/100\n",
            "2/2 - 0s - loss: 2.9306e-07 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8333 - 65ms/epoch - 33ms/step\n",
            "Epoch 77/100\n",
            "2/2 - 0s - loss: 2.9306e-07 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8333 - 66ms/epoch - 33ms/step\n",
            "Epoch 78/100\n",
            "2/2 - 0s - loss: 2.9306e-07 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
            "Epoch 79/100\n",
            "2/2 - 0s - loss: 2.8809e-07 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
            "Epoch 80/100\n",
            "2/2 - 0s - loss: 2.8809e-07 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8333 - 67ms/epoch - 34ms/step\n",
            "Epoch 81/100\n",
            "2/2 - 0s - loss: 2.8809e-07 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.8333 - 54ms/epoch - 27ms/step\n",
            "Epoch 82/100\n",
            "2/2 - 0s - loss: 2.8809e-07 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8333 - 76ms/epoch - 38ms/step\n",
            "Epoch 83/100\n",
            "2/2 - 0s - loss: 2.8809e-07 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8333 - 73ms/epoch - 37ms/step\n",
            "Epoch 84/100\n",
            "2/2 - 0s - loss: 2.8809e-07 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.8333 - 61ms/epoch - 30ms/step\n",
            "Epoch 85/100\n",
            "2/2 - 0s - loss: 2.8312e-07 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8333 - 55ms/epoch - 27ms/step\n",
            "Epoch 86/100\n",
            "2/2 - 0s - loss: 2.8312e-07 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
            "Epoch 87/100\n",
            "2/2 - 0s - loss: 2.7319e-07 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
            "Epoch 88/100\n",
            "2/2 - 0s - loss: 2.7319e-07 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.8333 - 68ms/epoch - 34ms/step\n",
            "Epoch 89/100\n",
            "2/2 - 0s - loss: 2.7319e-07 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8333 - 59ms/epoch - 30ms/step\n",
            "Epoch 90/100\n",
            "2/2 - 0s - loss: 2.7319e-07 - accuracy: 1.0000 - val_loss: 0.6854 - val_accuracy: 0.8333 - 54ms/epoch - 27ms/step\n",
            "Epoch 91/100\n",
            "2/2 - 0s - loss: 2.6822e-07 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8333 - 59ms/epoch - 29ms/step\n",
            "Epoch 92/100\n",
            "2/2 - 0s - loss: 2.6822e-07 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.8333 - 90ms/epoch - 45ms/step\n",
            "Epoch 93/100\n",
            "2/2 - 0s - loss: 2.6822e-07 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8333 - 66ms/epoch - 33ms/step\n",
            "Epoch 94/100\n",
            "2/2 - 0s - loss: 2.6325e-07 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8333 - 87ms/epoch - 43ms/step\n",
            "Epoch 95/100\n",
            "2/2 - 0s - loss: 2.5829e-07 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.8333 - 63ms/epoch - 31ms/step\n",
            "Epoch 96/100\n",
            "2/2 - 0s - loss: 2.5829e-07 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.8333 - 66ms/epoch - 33ms/step\n",
            "Epoch 97/100\n",
            "2/2 - 0s - loss: 2.5829e-07 - accuracy: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.8333 - 65ms/epoch - 32ms/step\n",
            "Epoch 98/100\n",
            "2/2 - 0s - loss: 2.5332e-07 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
            "Epoch 99/100\n",
            "2/2 - 0s - loss: 2.5332e-07 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8333 - 139ms/epoch - 70ms/step\n",
            "Epoch 100/100\n",
            "2/2 - 0s - loss: 2.5332e-07 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8333 - 123ms/epoch - 61ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWOaAUb_hveM",
        "outputId": "8311a3fb-6cc4-47f8-e98f-183b18d278e3"
      },
      "id": "nWOaAUb_hveM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2108 - accuracy: 0.5455\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.210814952850342, 0.5454545617103577]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "jbdltUT-h2r2",
        "outputId": "bff59a6b-aea5-46a7-b01b-d15cae9c38f3"
      },
      "id": "jbdltUT-h2r2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xcdX3/8dc7m2Q394QkCGYDiRgD2MptCVT8CQhWBCVFQRNbTbyAUlHQUguWQkT5tf1JrbVSbBS5qQQEpIFGUSIieM0CIUAAiTHAhosxl012k70ln98f52yYTHazs8mcmdmd9/PxmEfm3Ga+ZwfmPd/v95zvVxGBmZlVryHlLoCZmZWXg8DMrMo5CMzMqpyDwMysyjkIzMyqnIPAzKzKOQisKkiaJikkDS1g3/mSHipFucwqgYPAKo6kNZI6JE3KW/9o+mU+rTwl26UsoyW1SPphuctitq8cBFap/gDM7V6Q9OfAyPIVZzfvBdqBt0s6oJRvXEitxqw/HARWqW4GPpSzPA+4KXcHSeMk3SRpnaTnJF0maUi6rUbS1ZL+JGk1cEYPx14n6SVJayV9SVJNP8o3D/gGsAL4m7zXfoukX0raJOkFSfPT9SMk/Vta1mZJD6XrTpLUlPcaaySdmj5fIOl2Sd+RtBmYL2mWpF+l7/GSpK9LGp5z/Bsl/UTSBkmvSPq8pAMkbZU0MWe/o9O/37B+nLsNMg4Cq1S/BsZKOiz9gp4DfCdvn/8ExgGvA04kCY4Pp9vOBd4FHAU0AGfnHXsD0AW8Pt3nL4GPFVIwSQcDJwHfTR8fytv2w7Rsk4EjgeXp5quBY4A3A/sBnwN2FPKewGzgdmB8+p7bgc8Ak4C/AE4B/jYtwxjgPuBHwGvTc1waES8DPwPel/O6HwQWRURngeWwwSgi/PCjoh7AGuBU4DLgn4HTgJ8AQ4EApgE1QAdweM5xHwd+lj7/KfCJnG1/mR47FHgNSbPOiJztc4H70+fzgYf2UL7LgOXp8ykkX8pHpcuXAj/o4ZghwDbgiB62nQQ09fQ3SJ8vAH7ex9/sou73Tc/l0V72ez/wi/R5DfAyMKvcn7kf5X24rdEq2c3Az4Hp5DULkfwSHgY8l7PuOZIvZkh+Cb+Qt63bwemxL0nqXjckb/89+RDwTYCIWCvpAZKmokeBqcDvezhmElDXy7ZC7FI2SW8AvkJS2xlJEnAPp5t7KwPA/wDfkDQdmAk0R8Rv97JMNki4acgqVkQ8R9JpfDpwZ97mPwGdJF/q3Q4C1qbPXyL5Qszd1u0FkhrBpIgYnz7GRsQb+yqTpDcDM4BLJb0s6WXgOOADaSfuC8AhPRz6J6Ctl22t5HSEp01hk/P2yR8m+FrgaWBGRIwFPg90p9oLJM1lu4mINuA2kn6ND5KErVU5B4FVuo8Cb4uI1tyVEbGd5AvtKklj0rb5z/JqP8JtwKcl1UuaAFySc+xLwI+Bf5M0VtIQSYdIOrGA8swjaaY6nKT9/0jgz4ARwDtJ2u9PlfQ+SUMlTZR0ZETsAL4NfEXSa9PO7L+QVAv8DqiTdEbaaXsZUNtHOcYAm4EWSYcC5+dsuwc4UNJFkmrTv89xOdtvImn+OhMHgeEgsAoXEb+PiMZeNn+K5Nf0auAh4HskX7aQNN3cCzwGPMLuNYoPAcOBlcBGko7YA/dUFkl1JB2t/xkRL+c8/kDyhTovIp4nqcH8HbCBpKP4iPQlLgYeB5al2/4VGBIRzSQdvd8iqdG0ArtcRdSDi4EPAFvSc721e0NEbAHeDrybpA/gWeDknO2/IOmkfiStdVmVU4QnpjGrNpJ+CnwvIr5V7rJY+TkIzKqMpGNJmremprUHq3JuGjKrIpJuJLnH4CKHgHVzjcDMrMq5RmBmVuUG3A1lkyZNimnTppW7GGZmA8rDDz/8p4jIvz8FGIBBMG3aNBobe7ua0MzMeiKp10uF3TRkZlblHARmZlXOQWBmVuUcBGZmVc5BYGZW5TILAknflvRHSU/0sl2SviZplaQVko7OqixmZta7LGsEN5DMLNWbd5KM6z4DOI9kfHUzMyuxzO4jiIifS5q2h11mAzdFMsbFryWNl3RgOlZ82e3YEdzwyzVs2tpR7qKYmQFwymGv4Yip44v+uuW8oWwKu06/15Su2y0IJJ1HUmvgoIMOyt+ciVXrWrjynpXp+5fkLc3M9mj/sXWDLggKFhELgYUADQ0NJRklb0tbJwA3fmQWJ76hx7uyzcwGhXJeNbSWXeeUrefV+WbLrqV9OwCjhteUuSRmZtkqZxAsBj6UXj10PNBcKf0DAK3tXQCMqh0QlSYzs72W2becpFuAk4BJkpqAK4BhABHxDWAJydyuq4CtwIezKsveaEmDYLSDwMwGuSyvGprbx/YAPpnV+++rra4RmFmV8J3FvWjtSPoIRrqPwMwGOQdBL1rauxg6RNQO9Z/IzAY3f8v1Ymt7F6NqhyLfRGBmg5yDoBct7dvdUWxmVcFB0IvW9i73D5hZVXAQ9KK1o8tXDJlZVXAQ9KK1vctNQ2ZWFRwEvWht3+6mITOrCg6CXrS4RmBmVcJB0Iut7iMwsyrhIOhFa/t2B4GZVQUHQQ86unbQsX2Hh6A2s6rgIOiBh6A2s2riIOhBa4eHoDaz6uEg6EFr9+xkDgIzqwIOgh50T0ozstZ9BGY2+DkIetDq2cnMrIo4CHqwNe0jGDXcQWBmg5+DoActaR+BawRmVg0cBD1odR+BmVURB0EPfPmomVWTTINA0mmSnpG0StIlPWw/WNJSSSsk/UxSfZblKVRrexc1nq/YzKpEZt90kmqAa4B3AocDcyUdnrfb1cBNEfEm4Ergn7MqT3+0tm9n1PAaz1dsZlUhy5+8s4BVEbE6IjqARcDsvH0OB36aPr+/h+1l0dLukUfNrHpkGQRTgBdylpvSdbkeA96TPj8LGCNpYv4LSTpPUqOkxnXr1mVS2FwegtrMqkm5G8EvBk6U9ChwIrAW2J6/U0QsjIiGiGiYPHly5oVq8RDUZlZFsvy2WwtMzVmuT9ftFBEvktYIJI0G3hsRmzIsU0Fa27s8BLWZVY0sawTLgBmSpksaDswBFufuIGmSpO4yXAp8O8PyFKzVfQRmVkUyC4KI6AIuAO4FngJui4gnJV0p6cx0t5OAZyT9DngNcFVW5emP1g7PV2xm1SPTb7uIWAIsyVt3ec7z24HbsyzD3kimqXTTkJlVh3J3FleklvYuDzhnZlXDQZCnc/sOOrp2uI/AzKqGgyDPVs9OZmZVxkGQp2XngHPuIzCz6uAgyLNzCGr3EZhZlXAQ5PE0lWZWbRwEeVrdR2BmVcZBkKclrRH4PgIzqxYOgjzdTUO+j8DMqoWDIM/Wju4agYPAzKqDgyBPS9pH4M5iM6sWDoI8re1dDBHUDfOfxsyqg3/25mntSMYZqqj5irdthO2d5S6FmZXb8NEwfGTRX9ZBkKfi5iL4w4Nw47vKXQozqwRnfAWO/WjRX7aCvvEqQ8UNQb1+VfLvKVdA3djylsXMyuvgN2fysg6CPC3tFTYpTVtz8u9xH4fho8pbFjMblNwjmmdrR1dljTPUvhmGDIVhxW8XNDMDB8FuWtq3V1YfQVsz1I2DSuq8NrNBxUGQp7W9q7KGoO4OAjOzjDgI8rS2dzGyEmsEZmYZyTQIJJ0m6RlJqyRd0sP2gyTdL+lRSSsknZ5leQrR2lGBncW1vlrIzLKTWRBIqgGuAd4JHA7MlXR43m6XAbdFxFHAHOC/sipPIbq276Ctc0dlDTjnGoGZZSzLGsEsYFVErI6IDmARMDtvnwC6f+6OA17MsDx9au3onovAfQRmVj2y/Ok7BXghZ7kJOC5vnwXAjyV9ChgFnJphefpUkSOPOgjMLGPl7iyeC9wQEfXA6cDNknYrk6TzJDVKaly3bl1mhdk5F0GlBEFXB3Ruhbrx5S6JmQ1iWQbBWmBqznJ9ui7XR4HbACLiV0AdMCn/hSJiYUQ0RETD5MmTMypu7hDUFdI01L45+dc1AjPLUJZBsAyYIWm6pOEkncGL8/Z5HjgFQNJhJEGQ3U/+PjRvS0b4HFs3rFxF2FX38BIOAjPLUGZBEBFdwAXAvcBTJFcHPSnpSklnprv9HXCupMeAW4D5ERFZlakv61vaAZg4urZcRdhV26bkXweBmWUo08bwiFgCLMlbd3nO85XACVmWoT82tHYAsN+o4WUuSco1AjMrgXJ3FleU9a0dDKsRY+sqpLPYQWBmJeAgyLGhpYMJI4dXzuxkbe4sNrPsOQhyrG9tr5z+AXCNwMxKwkGQY31rBxMrpX8AkiBQjSekMbNMOQhybGjtqJyOYvBcBGZWEg6CHBtaKjEIPPKomWXLQZBq79rOlvYuJo2utCBw/4CZZctBkHr1HoIK6yx2EJhZxhwEqfUtFXYzGTgIzKwkHASp7hrBRDcNmVmVcRCk1rem4wxVXI3AQ1CbWbYcBKnupqGJldJHsL0TOltdIzCzzDkIUhtaOxg6RIwdUSnjDHl4CTMrDQdBakNrBxNGVdI4Qx6C2sxKo6AgkHSnpDN6mkZysPhTSwUOLwEOAjPLXKFf7P8FfAB4VtK/SJqZYZnKYkNre+VdMQQOAjPLXEFBEBH3RcRfA0cDa4D7JP1S0oclVci8jvsmGWeoQjqKwfMVm1nJFNzUI2kiMB/4GPAo8B8kwfCTTEpWYhU58ig4CMwscwVdIiPpB8BM4Gbg3RHxUrrpVkmNWRWuVNq7trOlrctBYGZVqdBrJb8WEff3tCEiGopYnrLY2NoJwH6V1kegITB8dLlLYmaDXKFNQ4dL2nmLq6QJkv42ozKVXMXeVVw71nMRmFnmCg2CcyNiU/dCRGwEzu3rIEmnSXpG0ipJl/Sw/d8lLU8fv5O0qafXyZpHHjWzalZo01CNJEVEAEiqAfb48znd5xrg7UATsEzS4ohY2b1PRHwmZ/9PAUf1s/xFsXN4iUprGnIQmFkJFFoj+BFJx/Apkk4BbknX7cksYFVErI6IDmARMHsP+89NX7fk1nePPFppTUMOAjMrgUJrBP8AfBw4P13+CfCtPo6ZAryQs9wEHNfTjpIOBqYDP+1l+3nAeQAHHXRQgUUu3IbWdmqGiLF1FXRLRFsz7Pe6cpfCzKpAQUEQETuAa9NHFuYAt0fE9l7efyGwEKChoSGK/eYbWjuYMHI4Q4ZUUMesh6A2sxIp9D6CGcA/A4cDdd3rI2JPP1nXAlNzluvTdT2ZA3yykLJk4U8tHZU1VzG4acjMSqbQPoLrSWoDXcDJwE3Ad/o4ZhkwQ9J0ScNJvuwX5+8k6VBgAvCrQgtdbMnwEhUUBNu7oKPFQWBmJVFoEIyIiKWAIuK5iFgAnLGnAyKiC7gAuBd4CrgtIp6UdKWkM3N2nQMs6r4iqRwqLgg8zpCZlVChncXt6RDUz0q6gKSJp89bXiNiCbAkb93lecsLCixDZta3tFfYFUOei8DMSqfQGsGFwEjg08AxwN8A87IqVCl1dO1gc1sXE0dX0s1krhGYWen0WSNIbwx7f0RcDLQAH868VCW0cWv3XcWVVCPwgHNmVjp91gjSSzrfUoKylMWrk9Y7CMysOhXaR/CopMXA94HW7pURcWcmpcrYCxu28uV7n6Fz+45X7youdtPQ8u/BMz98dXnm6XDk3N73f/lxePDfYMd2aE7vw3MQmFkJFBoEdcB64G056wIYkEFw75Mvs/ixF5mx/2gkOObgCcx8zZjivsmvroGNz8G4emhugg2r9xwET/4geUw+LFk+5G0w5oDilsnMrAeF3lk8qPoFmjZuY3TtUH78mbeirIZ5bmuGw94NZ10LP/gErPlF3/uP2A8++etsymNm1otC7yy+nqQGsIuI+EjRS1QCTRu3UT9hRHYhALveGVw37tV2/0L2NzMroUKbhu7JeV4HnAW8WPzilMbaTUkQZGbH9uSmsNwgaN8MO3bAkF765x0EZlYmhTYN3ZG7LOkW4KFMSlQCTRu3MmvahOzeIP/O4LpxQCTrR/QykJyDwMzKpNAbyvLNAPYvZkFKpXlbJ1vauqifMDK7N8m//LP73z01DzkIzKxMCu0j2MKufQQvk8xRMOA0bdwKkG3TUP6dwQ4CM6tghTYNFfnayvJp2rgNoDw1gu4mox6P2ewgMLOyKKhpSNJZksblLI+X9FfZFSs7rwZBljWCfjYNbe+EzlZPRGNmZVFoH8EVEbHzWywiNgFXZFOkbDVt3Mqo4TWMH5nhtJT9DQIPMmdmZVRoEPS0X6GXnlaUtRu3UT9hZPb3EEA/gsDDTptZ+RQaBI2SviLpkPTxFeDhLAuWlaaN25iSZbMQvPqFX5t2rdSO3XV9b/vXjc22XGZmPSg0CD4FdAC3AouANso4x/C+aNq4Ndv+AUi+2GvHwpCaZHlIDQwfU0AQuEZgZqVX6FVDrcAlGZclc83bOtnc1lWaIMj/Ut/TMBMOAjMro0KvGvqJpPE5yxMk3ZtdsbKxthSXjoKDwMwGlEKbhialVwoBEBEbGYB3FpfkZjJwEJjZgFJoEOyQdFD3gqRp9DAaaaUryc1ksIcg2NT7/hoCw0dnWy4zsx4UGgT/CDwk6WZJ3wEeAC7t6yBJp0l6RtIqST32MUh6n6SVkp6U9L3Ci95/TRu3MXJ4DROyvIcA9q5GUDcOsryk1cysF4V2Fv9IUgNwHvAocBewbU/HpJPeXwO8HWgClklaHBErc/aZQRIoJ0TERkmZNjet3bSVKeMznocA9j4IzMzKoNBB5z4GXAjUA8uB44FfsevUlflmAasiYnX6GouA2cDKnH3OBa5J+xyIiD/29wT6o3tCmkzt2LHrXATd6sYldxD3NCeBg8DMyqjQpqELgWOB5yLiZOAooJcG752mAC/kLDel63K9AXiDpF9I+rWk03p6IUnnSWqU1Lhu3boCi7y7pvSu4kx1pAO19hQERLo9j4PAzMqo0CBoi4g2AEm1EfE0MLMI7z+UZG6Dk4C5wDdzL1PtFhELI6IhIhomT568V2+0ua2T5m2dpbliCHoJAl4dVyhXTzUIM7MSKXS8oKb0C/ou4CeSNgLP9XHMWmBqznJ9um6X1wV+ExGdwB8k/Y4kGJYVWK6ClfQeAthDEDSz658F1wjMrKwK7Sw+K326QNL9wDjgR30ctgyYIWk6SQDMAT6Qt89dJDWB6yVNImkqWl1g2fulJMNPQ4FB0MMxHoLazMqk3yOIRsQDBe7XJekC4F6gBvh2RDwp6UqgMSIWp9v+UtJKYDvw9xGxvr9lKkRJbyaDwoNgexd0tLhGYGZlk+lQ0hGxBFiSt+7ynOcBfDZ9ZOqwA8fykROms9+o4dm+0c6RR/NGEq3rZQTS7lnL8vc3MyuRATmnwN44/nUTOf51E7N/o15rBON33b5zf89FYGblVehVQ1ao3moEvc1J4HGGzKzMHATF1taczD1Qk1fZqhmajCXkIDCzCuMgKLY9XQra0zATDgIzKzMHQbH1GQSbdt+/e5uZWRk4CIrNNQIzG2AcBMXWtqn/QeC5CMysjBwExda2h3GDeguC2rG7j0hqZlYi/vYptr1pGnKzkJmVkYOgmHqbi6Bb3bhke+TM8rmnGoSZWQk4CIqpowVix56DIHYk+3VzjcDMysxBUEx9XQHU08BzDgIzKzMHQTHtdRB4CGozKx8HQTHtDIJeRhLtabyhtube9zczKwEHQTH1t0awvSuZw9hNQ2ZWRg6CYupvEHTPReAgMLMychAU084g6KXNP39OAg8vYWYVwEFQTL3NRdAtf5YyB4GZVQAHQTG1NSdjBuXPRdCtZhgMG+UgMLOK4iAopkLuCcgditpBYGYVINMgkHSapGckrZJ0SQ/b50taJ2l5+vhYluXJ3J5GHu2WO96Qg8DMKkBmk9dLqgGuAd4ONAHLJC2OiJV5u94aERdkVY6S2tM4Q90cBGZWYbKsEcwCVkXE6ojoABYBszN8v/IrtGlo84vwhwfhlScBJXMcm5mVSZZBMAV4IWe5KV2X772SVki6XdLUnl5I0nmSGiU1rlu3LouyFkf33AJ7MuYAWL8KbnwXPPa9ZNlzEZhZGWXWNFSgu4FbIqJd0seBG4G35e8UEQuBhQANDQ2Rv71itDXDiD7GDXrHVfDn57y6PP6gbMtkZtaHLINgLZD7C78+XbdTRKzPWfwW8P8yLE+2IgprGqodA9P/T2nKZGZWgCzbJJYBMyRNlzQcmAMszt1B0oE5i2cCT2VYnmz1NReBmVmFyqxGEBFdki4A7gVqgG9HxJOSrgQaI2Ix8GlJZwJdwAZgflblyVxfdxWbmVWoTPsIImIJsCRv3eU5zy8FLs2yDCXjS0HNbIDy5SrF4iAwswHKQVAsDgIzG6AcBMXiIDCzAcpBUCx9zUVgZlahHATF0td8xWZmFcpBUCxtzclcAzXDyl0SM7N+cRAUSyF3FZuZVSAHQbE4CMxsgHIQFIuDwMwGKAdBsTgIzGyAchAUi4PAzAYoB0GxtDX70lEzG5AcBMVQ6FwEZmYVyEFQDB2tENsdBGY2IDkIisHjDJnZAOYgKAYHgZkNYOWevH5wcBCY7ZXOzk6amppoa2srd1EGjbq6Ourr6xk2rPDhbhwExeAgMNsrTU1NjBkzhmnTpiGp3MUZ8CKC9evX09TUxPTp0ws+zk1DxeAhqM32SltbGxMnTnQIFIkkJk6c2O8aloOgGFwjMNtrDoHi2pu/p4OgGNrTIKj1DWVmNvBkGgSSTpP0jKRVki7Zw37vlRSSGrIsT2bammHYSBg6vNwlMbN+WL9+PUceeSRHHnkkBxxwAFOmTNm53NHRscdjGxsb+fSnP12ikmYrs85iSTXANcDbgSZgmaTFEbEyb78xwIXAb7IqS+Z8V7HZgDRx4kSWL18OwIIFCxg9ejQXX3zxzu1dXV0MHdrz12RDQwMNDQPzt2u+LK8amgWsiojVAJIWAbOBlXn7fRH4V+DvMyxLthwEZvvsC3c/ycoXNxf1NQ9/7ViuePcb+3XM/Pnzqaur49FHH+WEE05gzpw5XHjhhbS1tTFixAiuv/56Zs6cyc9+9jOuvvpq7rnnHhYsWMDzzz/P6tWref7557nooosGVG0hyyCYAryQs9wEHJe7g6SjgakR8b+Seg0CSecB5wEcdNBBGRR1HzkIzAaVpqYmfvnLX1JTU8PmzZt58MEHGTp0KPfddx+f//znueOOO3Y75umnn+b+++9ny5YtzJw5k/PPP79f1/KXU9nuI5A0BPgKML+vfSNiIbAQoKGhIbIt2V5oa4aRk8pdCrMBrb+/3LN0zjnnUFNTA0BzczPz5s3j2WefRRKdnZ09HnPGGWdQW1tLbW0t+++/P6+88gr19fWlLPZey7KzeC0wNWe5Pl3XbQzwZ8DPJK0BjgcWD8gOY9cIzAaVUaNG7Xz+T//0T5x88sk88cQT3H333b1eo19bW7vzeU1NDV1dXZmXs1iyDIJlwAxJ0yUNB+YAi7s3RkRzREyKiGkRMQ34NXBmRDRmWKZsOAjMBq3m5mamTJkCwA033FDewmQksyCIiC7gAuBe4Cngtoh4UtKVks7M6n1LznMRmA1qn/vc57j00ks56qijBtSv/P5QROU1ue9JQ0NDNDZWUKWhoxX+72vh1C/AWy4qd2nMBpSnnnqKww47rNzFGHR6+rtKejgiemx6953F+8rDS5jZAOcg2FcOAjMb4BwE+8pBYGYDnINgX3kIajMb4BwE+6otvSXeNQIzG6AcBPuqbVPyr4PAzAYoB8G+2tk05LkIzAaak08+mXvvvXeXdV/96lc5//zze9z/pJNOovvy9dNPP51Nmzbtts+CBQu4+uqr9/i+d911FytXvjr+5uWXX859993X3+IXjYNgX7U1w9ARMLS2733NrKLMnTuXRYsW7bJu0aJFzJ07t89jlyxZwvjxe9c3mB8EV155JaeeeupevVYxePL6fdXW7NqAWTH88BJ4+fHivuYBfw7v/JdeN5999tlcdtlldHR0MHz4cNasWcOLL77ILbfcwmc/+1m2bdvG2WefzRe+8IXdjp02bRqNjY1MmjSJq666ihtvvJH999+fqVOncswxxwDwzW9+k4ULF9LR0cHrX/96br75ZpYvX87ixYt54IEH+NKXvsQdd9zBF7/4Rd71rndx9tlns3TpUi6++GK6uro49thjufbaa6mtrWXatGnMmzePu+++m87OTr7//e9z6KGHFuXP5BrBvvLwEmYD1n777cesWbP44Q9/CCS1gfe9731cddVVNDY2smLFCh544AFWrFjR62s8/PDDLFq0iOXLl7NkyRKWLVu2c9t73vMeli1bxmOPPcZhhx3Gddddx5vf/GbOPPNMvvzlL7N8+XIOOeSQnfu3tbUxf/58br31Vh5//HG6urq49tprd26fNGkSjzzyCOeff36fzU/94RrBvnIQmBXHHn65Z6m7eWj27NksWrSI6667jttuu42FCxfS1dXFSy+9xMqVK3nTm97U4/EPPvggZ511FiNHjgTgzDNfHUrtiSee4LLLLmPTpk20tLTwjne8Y49leeaZZ5g+fTpveMMbAJg3bx7XXHMNF12UDF/znve8B4BjjjmGO++8c5/PvZtrBPvKQWA2oM2ePZulS5fyyCOPsHXrVvbbbz+uvvpqli5dyooVKzjjjDN6HXq6L/Pnz+frX/86jz/+OFdcccVev0637qGuiz3MtYNgXzkIzAa00aNHc/LJJ/ORj3yEuXPnsnnzZkaNGsW4ceN45ZVXdjYb9eatb30rd911F9u2bWPLli3cfffdO7dt2bKFAw88kM7OTr773e/uXD9mzBi2bNmy22vNnDmTNWvWsGrVKgBuvvlmTjzxxCKdae+qp2nokZvhV18v/utuXAPT31r81zWzkpk7dy5nnXUWixYt4tBDD+Woo47i0EMPZerUqZxwwgl7PPboo4/m/e9/P0cccQT7778/xx577M5tX/ziFznuuOOYPHkyxx133M4v/zlz5nDuuefyta99jdtvv33n/nV1dVx//fWcc845OzuLP/GJT2Rz0jmqZxjqp/8XVtxa/AIhOP5v4aDj+t7VzHbhYaiz0d9hqKunRnDoGcnDzMx24T4CM7Mq5yAws7IaaM3TlYhMwB8AAAXkSURBVG5v/p4OAjMrm7q6OtavX+8wKJKIYP369dTV1fXruOrpIzCzilNfX09TUxPr1q0rd1EGjbq6Ourr6/t1jIPAzMpm2LBhTJ8+vdzFqHpuGjIzq3IOAjOzKucgMDOrcgPuzmJJ64Dn9vLwScCfilicgaIaz7sazxmq87yr8Zyh/+d9cERM7mnDgAuCfSGpsbdbrAezajzvajxnqM7zrsZzhuKet5uGzMyqnIPAzKzKVVsQLCx3AcqkGs+7Gs8ZqvO8q/GcoYjnXVV9BGZmtrtqqxGYmVkeB4GZWZWrmiCQdJqkZyStknRJucuTBUlTJd0vaaWkJyVdmK7fT9JPJD2b/juh3GUtNkk1kh6VdE+6PF3Sb9LP+1ZJw8tdxmKTNF7S7ZKelvSUpL+oks/6M+l/309IukVS3WD7vCV9W9IfJT2Rs67Hz1aJr6XnvkLS0f19v6oIAkk1wDXAO4HDgbmSDi9vqTLRBfxdRBwOHA98Mj3PS4ClETEDWJouDzYXAk/lLP8r8O8R8XpgI/DRspQqW/8B/CgiDgWOIDn/Qf1ZS5oCfBpoiIg/A2qAOQy+z/sG4LS8db19tu8EZqSP84Br+/tmVREEwCxgVUSsjogOYBEwu8xlKrqIeCkiHkmfbyH5YphCcq43prvdCPxVeUqYDUn1wBnAt9JlAW8DumcFH4znPA54K3AdQER0RMQmBvlnnRoKjJA0FBgJvMQg+7wj4ufAhrzVvX22s4GbIvFrYLykA/vzftUSBFOAF3KWm9J1g5akacBRwG+A10TES+mml4HXlKlYWfkq8DlgR7o8EdgUEV3p8mD8vKcD64Dr0yaxb0kaxSD/rCNiLXA18DxJADQDDzP4P2/o/bPd5++3agmCqiJpNHAHcFFEbM7dFsn1woPmmmFJ7wL+GBEPl7ssJTYUOBq4NiKOAlrJawYabJ81QNouPpskCF8LjGL3JpRBr9ifbbUEwVpgas5yfbpu0JE0jCQEvhsRd6arX+muKqb//rFc5cvACcCZktaQNPm9jaTtfHzadACD8/NuApoi4jfp8u0kwTCYP2uAU4E/RMS6iOgE7iT5b2Cwf97Q+2e7z99v1RIEy4AZ6ZUFw0k6lxaXuUxFl7aNXwc8FRFfydm0GJiXPp8H/E+py5aViLg0IuojYhrJ5/rTiPhr4H7g7HS3QXXOABHxMvCCpJnpqlOAlQzizzr1PHC8pJHpf+/d5z2oP+9Ub5/tYuBD6dVDxwPNOU1IhYmIqngApwO/A34P/GO5y5PROb6FpLq4AliePk4naTNfCjwL3AfsV+6yZnT+JwH3pM9fB/wWWAV8H6gtd/kyON8jgcb0874LmFANnzXwBeBp4AngZqB2sH3ewC0kfSCdJLW/j/b22QIiuSry98DjJFdU9ev9PMSEmVmVq5amITMz64WDwMysyjkIzMyqnIPAzKzKOQjMzKqcg8CshCSd1D1CqlmlcBCYmVU5B4FZDyT9jaTfSlou6b/T+Q5aJP17Ohb+UkmT032PlPTrdCz4H+SME/96SfdJekzSI5IOSV9+dM48At9N75A1KxsHgVkeSYcB7wdOiIgjge3AX5MMcNYYEW8EHgCuSA+5CfiHiHgTyZ2d3eu/C1wTEUcAbya5UxSSUWEvIpkb43UkY+WYlc3QvncxqzqnAMcAy9If6yNIBvjaAdya7vMd4M50XoDxEfFAuv5G4PuSxgBTIuIHABHRBpC+3m8joildXg5MAx7K/rTMeuYgMNudgBsj4tJdVkr/lLff3o7P0p7zfDv+/9DKzE1DZrtbCpwtaX/YOVfswST/v3SPcPkB4KGIaAY2Svo/6foPAg9EMkNck6S/Sl+jVtLIkp6FWYH8S8QsT0SslHQZ8GNJQ0hGgPwkyeQvs9JtfyTpR4BkSOBvpF/0q4EPp+s/CPy3pCvT1zinhKdhVjCPPmpWIEktETG63OUwKzY3DZmZVTnXCMzMqpxrBGZmVc5BYGZW5RwEZmZVzkFgZlblHARmZlXu/wPZWea/BhYiPgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with one hidden layer"
      ],
      "metadata": {
        "id": "VCdYFGFriQSo"
      },
      "id": "VCdYFGFriQSo"
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = Sequential()\n",
        "model4.add(Dense(64, activation='relu',input_dim=X_train.shape[1]))\n",
        "model4.add(Dense(32, activation='relu'))\n",
        "model4.add(Dense(2, activation='sigmoid')) #output layer\n",
        "model4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxN3QsFoh9CG",
        "outputId": "62c858a6-efdd-4be8-f0f2-fa4c7ac1b9d1"
      },
      "id": "sxN3QsFoh9CG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_19 (Dense)            (None, 64)                14016     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,162\n",
            "Trainable params: 16,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history=model4.fit(X_train,y_train,epochs=100,verbose=2,validation_split=0.2,batch_size=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ5o-hehiUVo",
        "outputId": "7404fd14-9439-4a6c-c7e4-2454982a2b88"
      },
      "id": "sQ5o-hehiUVo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 - 1s - loss: 0.6854 - accuracy: 0.6250 - val_loss: 0.7106 - val_accuracy: 0.5000 - 1s/epoch - 690ms/step\n",
            "Epoch 2/100\n",
            "2/2 - 0s - loss: 0.6684 - accuracy: 0.7500 - val_loss: 0.7167 - val_accuracy: 0.3333 - 47ms/epoch - 24ms/step\n",
            "Epoch 3/100\n",
            "2/2 - 0s - loss: 0.6544 - accuracy: 0.7500 - val_loss: 0.7224 - val_accuracy: 0.3333 - 43ms/epoch - 21ms/step\n",
            "Epoch 4/100\n",
            "2/2 - 0s - loss: 0.6413 - accuracy: 0.7500 - val_loss: 0.7282 - val_accuracy: 0.3333 - 67ms/epoch - 34ms/step\n",
            "Epoch 5/100\n",
            "2/2 - 0s - loss: 0.6279 - accuracy: 0.7500 - val_loss: 0.7336 - val_accuracy: 0.3333 - 97ms/epoch - 49ms/step\n",
            "Epoch 6/100\n",
            "2/2 - 0s - loss: 0.6144 - accuracy: 0.7917 - val_loss: 0.7393 - val_accuracy: 0.3333 - 79ms/epoch - 40ms/step\n",
            "Epoch 7/100\n",
            "2/2 - 0s - loss: 0.6010 - accuracy: 0.7917 - val_loss: 0.7454 - val_accuracy: 0.3333 - 89ms/epoch - 44ms/step\n",
            "Epoch 8/100\n",
            "2/2 - 0s - loss: 0.5875 - accuracy: 0.7917 - val_loss: 0.7515 - val_accuracy: 0.3333 - 93ms/epoch - 46ms/step\n",
            "Epoch 9/100\n",
            "2/2 - 0s - loss: 0.5737 - accuracy: 0.7917 - val_loss: 0.7584 - val_accuracy: 0.3333 - 78ms/epoch - 39ms/step\n",
            "Epoch 10/100\n",
            "2/2 - 0s - loss: 0.5605 - accuracy: 0.7917 - val_loss: 0.7656 - val_accuracy: 0.3333 - 79ms/epoch - 39ms/step\n",
            "Epoch 11/100\n",
            "2/2 - 0s - loss: 0.5451 - accuracy: 0.7917 - val_loss: 0.7716 - val_accuracy: 0.3333 - 46ms/epoch - 23ms/step\n",
            "Epoch 12/100\n",
            "2/2 - 0s - loss: 0.5301 - accuracy: 0.8333 - val_loss: 0.7780 - val_accuracy: 0.3333 - 81ms/epoch - 40ms/step\n",
            "Epoch 13/100\n",
            "2/2 - 0s - loss: 0.5137 - accuracy: 0.8333 - val_loss: 0.7837 - val_accuracy: 0.3333 - 51ms/epoch - 25ms/step\n",
            "Epoch 14/100\n",
            "2/2 - 0s - loss: 0.4980 - accuracy: 0.8750 - val_loss: 0.7901 - val_accuracy: 0.3333 - 56ms/epoch - 28ms/step\n",
            "Epoch 15/100\n",
            "2/2 - 0s - loss: 0.4804 - accuracy: 0.8750 - val_loss: 0.7958 - val_accuracy: 0.3333 - 86ms/epoch - 43ms/step\n",
            "Epoch 16/100\n",
            "2/2 - 0s - loss: 0.4627 - accuracy: 0.9583 - val_loss: 0.8029 - val_accuracy: 0.3333 - 58ms/epoch - 29ms/step\n",
            "Epoch 17/100\n",
            "2/2 - 0s - loss: 0.4448 - accuracy: 0.9583 - val_loss: 0.8111 - val_accuracy: 0.3333 - 79ms/epoch - 40ms/step\n",
            "Epoch 18/100\n",
            "2/2 - 0s - loss: 0.4265 - accuracy: 0.9583 - val_loss: 0.8202 - val_accuracy: 0.3333 - 89ms/epoch - 45ms/step\n",
            "Epoch 19/100\n",
            "2/2 - 0s - loss: 0.4068 - accuracy: 0.9583 - val_loss: 0.8288 - val_accuracy: 0.3333 - 80ms/epoch - 40ms/step\n",
            "Epoch 20/100\n",
            "2/2 - 0s - loss: 0.3870 - accuracy: 0.9583 - val_loss: 0.8370 - val_accuracy: 0.3333 - 86ms/epoch - 43ms/step\n",
            "Epoch 21/100\n",
            "2/2 - 0s - loss: 0.3674 - accuracy: 1.0000 - val_loss: 0.8450 - val_accuracy: 0.3333 - 79ms/epoch - 39ms/step\n",
            "Epoch 22/100\n",
            "2/2 - 0s - loss: 0.3468 - accuracy: 1.0000 - val_loss: 0.8521 - val_accuracy: 0.3333 - 43ms/epoch - 21ms/step\n",
            "Epoch 23/100\n",
            "2/2 - 0s - loss: 0.3274 - accuracy: 1.0000 - val_loss: 0.8599 - val_accuracy: 0.3333 - 45ms/epoch - 22ms/step\n",
            "Epoch 24/100\n",
            "2/2 - 0s - loss: 0.3077 - accuracy: 1.0000 - val_loss: 0.8683 - val_accuracy: 0.3333 - 47ms/epoch - 24ms/step\n",
            "Epoch 25/100\n",
            "2/2 - 0s - loss: 0.2883 - accuracy: 1.0000 - val_loss: 0.8773 - val_accuracy: 0.3333 - 39ms/epoch - 20ms/step\n",
            "Epoch 26/100\n",
            "2/2 - 0s - loss: 0.2701 - accuracy: 1.0000 - val_loss: 0.8861 - val_accuracy: 0.3333 - 74ms/epoch - 37ms/step\n",
            "Epoch 27/100\n",
            "2/2 - 0s - loss: 0.2517 - accuracy: 1.0000 - val_loss: 0.8956 - val_accuracy: 0.3333 - 40ms/epoch - 20ms/step\n",
            "Epoch 28/100\n",
            "2/2 - 0s - loss: 0.2339 - accuracy: 1.0000 - val_loss: 0.9045 - val_accuracy: 0.3333 - 54ms/epoch - 27ms/step\n",
            "Epoch 29/100\n",
            "2/2 - 0s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.9134 - val_accuracy: 0.3333 - 50ms/epoch - 25ms/step\n",
            "Epoch 30/100\n",
            "2/2 - 0s - loss: 0.2012 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.3333 - 49ms/epoch - 24ms/step\n",
            "Epoch 31/100\n",
            "2/2 - 0s - loss: 0.1852 - accuracy: 1.0000 - val_loss: 0.9287 - val_accuracy: 0.3333 - 44ms/epoch - 22ms/step\n",
            "Epoch 32/100\n",
            "2/2 - 0s - loss: 0.1708 - accuracy: 1.0000 - val_loss: 0.9334 - val_accuracy: 0.3333 - 45ms/epoch - 23ms/step\n",
            "Epoch 33/100\n",
            "2/2 - 0s - loss: 0.1558 - accuracy: 1.0000 - val_loss: 0.9390 - val_accuracy: 0.3333 - 37ms/epoch - 19ms/step\n",
            "Epoch 34/100\n",
            "2/2 - 0s - loss: 0.1430 - accuracy: 1.0000 - val_loss: 0.9415 - val_accuracy: 0.3333 - 41ms/epoch - 20ms/step\n",
            "Epoch 35/100\n",
            "2/2 - 0s - loss: 0.1305 - accuracy: 1.0000 - val_loss: 0.9441 - val_accuracy: 0.3333 - 48ms/epoch - 24ms/step\n",
            "Epoch 36/100\n",
            "2/2 - 0s - loss: 0.1192 - accuracy: 1.0000 - val_loss: 0.9448 - val_accuracy: 0.3333 - 38ms/epoch - 19ms/step\n",
            "Epoch 37/100\n",
            "2/2 - 0s - loss: 0.1080 - accuracy: 1.0000 - val_loss: 0.9458 - val_accuracy: 0.3333 - 41ms/epoch - 21ms/step\n",
            "Epoch 38/100\n",
            "2/2 - 0s - loss: 0.0975 - accuracy: 1.0000 - val_loss: 0.9455 - val_accuracy: 0.3333 - 48ms/epoch - 24ms/step\n",
            "Epoch 39/100\n",
            "2/2 - 0s - loss: 0.0892 - accuracy: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.3333 - 39ms/epoch - 20ms/step\n",
            "Epoch 40/100\n",
            "2/2 - 0s - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.9423 - val_accuracy: 0.3333 - 49ms/epoch - 25ms/step\n",
            "Epoch 41/100\n",
            "2/2 - 0s - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.9404 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 42/100\n",
            "2/2 - 0s - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.9385 - val_accuracy: 0.5000 - 39ms/epoch - 19ms/step\n",
            "Epoch 43/100\n",
            "2/2 - 0s - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.9354 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 44/100\n",
            "2/2 - 0s - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.9327 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 45/100\n",
            "2/2 - 0s - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.5000 - 41ms/epoch - 21ms/step\n",
            "Epoch 46/100\n",
            "2/2 - 0s - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.9242 - val_accuracy: 0.5000 - 39ms/epoch - 20ms/step\n",
            "Epoch 47/100\n",
            "2/2 - 0s - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.9197 - val_accuracy: 0.5000 - 39ms/epoch - 20ms/step\n",
            "Epoch 48/100\n",
            "2/2 - 0s - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.9152 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 49/100\n",
            "2/2 - 0s - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.9108 - val_accuracy: 0.5000 - 52ms/epoch - 26ms/step\n",
            "Epoch 50/100\n",
            "2/2 - 0s - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.9061 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 51/100\n",
            "2/2 - 0s - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.9020 - val_accuracy: 0.5000 - 53ms/epoch - 26ms/step\n",
            "Epoch 52/100\n",
            "2/2 - 0s - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.8978 - val_accuracy: 0.5000 - 45ms/epoch - 22ms/step\n",
            "Epoch 53/100\n",
            "2/2 - 0s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.8945 - val_accuracy: 0.5000 - 46ms/epoch - 23ms/step\n",
            "Epoch 54/100\n",
            "2/2 - 0s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.8914 - val_accuracy: 0.5000 - 46ms/epoch - 23ms/step\n",
            "Epoch 55/100\n",
            "2/2 - 0s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.8885 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 56/100\n",
            "2/2 - 0s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.8852 - val_accuracy: 0.5000 - 41ms/epoch - 21ms/step\n",
            "Epoch 57/100\n",
            "2/2 - 0s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.8824 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 58/100\n",
            "2/2 - 0s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.5000 - 45ms/epoch - 22ms/step\n",
            "Epoch 59/100\n",
            "2/2 - 0s - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.8772 - val_accuracy: 0.5000 - 44ms/epoch - 22ms/step\n",
            "Epoch 60/100\n",
            "2/2 - 0s - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.8741 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 61/100\n",
            "2/2 - 0s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.8717 - val_accuracy: 0.5000 - 53ms/epoch - 26ms/step\n",
            "Epoch 62/100\n",
            "2/2 - 0s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.8693 - val_accuracy: 0.5000 - 52ms/epoch - 26ms/step\n",
            "Epoch 63/100\n",
            "2/2 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.8666 - val_accuracy: 0.5000 - 50ms/epoch - 25ms/step\n",
            "Epoch 64/100\n",
            "2/2 - 0s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8647 - val_accuracy: 0.5000 - 43ms/epoch - 22ms/step\n",
            "Epoch 65/100\n",
            "2/2 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.8630 - val_accuracy: 0.5000 - 43ms/epoch - 21ms/step\n",
            "Epoch 66/100\n",
            "2/2 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.8614 - val_accuracy: 0.5000 - 45ms/epoch - 23ms/step\n",
            "Epoch 67/100\n",
            "2/2 - 0s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.8596 - val_accuracy: 0.5000 - 53ms/epoch - 26ms/step\n",
            "Epoch 68/100\n",
            "2/2 - 0s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8580 - val_accuracy: 0.5000 - 45ms/epoch - 23ms/step\n",
            "Epoch 69/100\n",
            "2/2 - 0s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.8565 - val_accuracy: 0.5000 - 44ms/epoch - 22ms/step\n",
            "Epoch 70/100\n",
            "2/2 - 0s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8551 - val_accuracy: 0.5000 - 44ms/epoch - 22ms/step\n",
            "Epoch 71/100\n",
            "2/2 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8535 - val_accuracy: 0.5000 - 51ms/epoch - 26ms/step\n",
            "Epoch 72/100\n",
            "2/2 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8522 - val_accuracy: 0.5000 - 57ms/epoch - 28ms/step\n",
            "Epoch 73/100\n",
            "2/2 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.8508 - val_accuracy: 0.5000 - 53ms/epoch - 26ms/step\n",
            "Epoch 74/100\n",
            "2/2 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8499 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 75/100\n",
            "2/2 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8491 - val_accuracy: 0.5000 - 39ms/epoch - 19ms/step\n",
            "Epoch 76/100\n",
            "2/2 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8482 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 77/100\n",
            "2/2 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8475 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 78/100\n",
            "2/2 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8469 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 79/100\n",
            "2/2 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8463 - val_accuracy: 0.5000 - 44ms/epoch - 22ms/step\n",
            "Epoch 80/100\n",
            "2/2 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8458 - val_accuracy: 0.5000 - 55ms/epoch - 27ms/step\n",
            "Epoch 81/100\n",
            "2/2 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8458 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 82/100\n",
            "2/2 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8462 - val_accuracy: 0.5000 - 43ms/epoch - 21ms/step\n",
            "Epoch 83/100\n",
            "2/2 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8462 - val_accuracy: 0.5000 - 43ms/epoch - 22ms/step\n",
            "Epoch 84/100\n",
            "2/2 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8462 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 85/100\n",
            "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8459 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 86/100\n",
            "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8456 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 87/100\n",
            "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8452 - val_accuracy: 0.5000 - 39ms/epoch - 20ms/step\n",
            "Epoch 88/100\n",
            "2/2 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8447 - val_accuracy: 0.5000 - 57ms/epoch - 28ms/step\n",
            "Epoch 89/100\n",
            "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8440 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 90/100\n",
            "2/2 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8431 - val_accuracy: 0.5000 - 39ms/epoch - 20ms/step\n",
            "Epoch 91/100\n",
            "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8422 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 92/100\n",
            "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8413 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 93/100\n",
            "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8407 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 94/100\n",
            "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8400 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 95/100\n",
            "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8394 - val_accuracy: 0.5000 - 46ms/epoch - 23ms/step\n",
            "Epoch 96/100\n",
            "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8386 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 97/100\n",
            "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8381 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 98/100\n",
            "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8373 - val_accuracy: 0.5000 - 51ms/epoch - 26ms/step\n",
            "Epoch 99/100\n",
            "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8367 - val_accuracy: 0.5000 - 39ms/epoch - 20ms/step\n",
            "Epoch 100/100\n",
            "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8361 - val_accuracy: 0.5000 - 49ms/epoch - 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogk9wW0riZ6h",
        "outputId": "069faa24-d176-46e6-ee4b-d892183b8e60"
      },
      "id": "Ogk9wW0riZ6h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 83ms/step - loss: 1.6615 - accuracy: 0.0909\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6615437269210815, 0.09090909361839294]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "uuG2NX_QiqJx",
        "outputId": "a721dbf6-c7f1-4455-8504-a410321d6082"
      },
      "id": "uuG2NX_QiqJx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3rTHkbUiuRh"
      },
      "id": "F3rTHkbUiuRh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}